{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3302ca6-cb54-4991-8bd0-9e86071d0f00",
   "metadata": {},
   "source": [
    "### Purpose of this notebook\n",
    "The purpose of this notebook is to download WLASL dataset and upload to S3 bucket after processing as Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b997ab6-08af-4c02-86a8-152f13e963fb",
   "metadata": {},
   "source": [
    "The videos will be labeled by the 'gloss' name from the Json.\n",
    "Some videos only have the required sign between Frame-A and Frame-B. These will be cropped accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ea70dc-4528-4568-870d-07de046eff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install missing packages\n",
    "#!pip install boto3\n",
    "#!pip install pyarrow\n",
    "#!pip install fastparquet\n",
    "#!pip install s3fs\n",
    "#!pip install mediapipe\n",
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae7a476-c650-46fa-b556-87fa80bf2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3 #Video files get read through this\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import s3fs # Parquet files get read through this\n",
    "import zlib # For compression\n",
    "import time # To calculate download time\n",
    "import configparser\n",
    "import requests\n",
    "import psutil # Checks memory usage\n",
    "import tempfile\n",
    "import json\n",
    "#import mediapipe as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acebc799-53d0-4abc-8877-27ce920c34d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/.aws/credentials']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the credentials file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/ec2-user/.aws/credentials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1bc54a8-c2b2-4b31-934b-d0a97eaa68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = config[\"default\"]['aws_access_key_id']\n",
    "aws_secret_access_key = config[\"default\"]['aws_secret_access_key']\n",
    "bucket_name = 'asl-capstone'\n",
    "prefix = '/WLASL/'\n",
    "save_path = '/content/temp_folder'\n",
    "s3_URI = 's3://asl-capstone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41445ca-7160-4280-83cc-ce7c0560e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an s3 object\n",
    "s3 = boto3.client('s3',aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key,\n",
    "                  region_name = 'us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6202d1-bcd3-4d8f-b862-9aeaafca1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3FS object\n",
    "fs = s3fs.S3FileSystem(key=aws_access_key_id, secret=aws_secret_access_key) # Define an S3FS object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60c62087-13c9-4d25-a613-83222f470a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlasl_files = fs.ls('s3://asl-capstone/wlasl/')\n",
    "len(wlasl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31920c2b-3d5f-4790-a77d-f7cdeab4005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "all_parquet_files = [file for file in wlasl_files if 'parquet' in file]\n",
    "print(len(all_parquet_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f06e006b-a0e4-4dff-808d-ea8d91986f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_parq = pd.DataFrame()\n",
    "for file in all_parquet_files:\n",
    "    tmp_parq = pd.concat([tmp_parq, pd.read_parquet('s3://' + file)])\n",
    "\n",
    "# tmp_parq.to_parquet('s3://asl-capstone/wlasl/video_mappings_masterfile.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e1a3cc6-b6c8-40f6-bcf6-19f3fb5f18c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11938, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_parq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "836d21d0-dcf3-42b4-aad1-e9ae6fca85b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlasl_files_cleaned = [file for file in wlasl_files if '_' in file and '.npy' in file]\n",
    "len(wlasl_files_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b660ca0e-49d5-492f-b8a2-068631f47eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_df = pd.DataFrame(columns=['filepath', 'word', 'frame_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45c35f09-8884-4e99-a920-955c3f847036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(wlasl_files_cleaned):\n",
    "    with fs.open(file, 'rb') as f:\n",
    "        vid = np.load(f).astype('float32')\n",
    "        \n",
    "    word = file.split('_')[0].split('/')[-1]\n",
    "    frames = len(vid)\n",
    "    \n",
    "    temp_df = pd.DataFrame([[file, word, frames]], columns=['filepath', 'word', 'frame_count'])\n",
    "    \n",
    "    vid_df = pd.concat([vid_df, temp_df])\n",
    "    vid_df.to_parquet('s3://asl-capstone/wlasl/video_mappings_1.parquet')\n",
    "\n",
    "    new_file_path = file.replace('/wlasl/', '/wlasl/RGB/')\n",
    "\n",
    "    with fs.open(new_file_path, 'wb') as f:\n",
    "        np.save(f, vid)\n",
    "\n",
    "    fs.rm(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b09665-8614-4a12-a4eb-05649b364592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
