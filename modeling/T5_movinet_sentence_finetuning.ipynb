{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT RUN THIS CODE IN THE NOTEBOOK - copy paste into terminal in the HOME directory!\n",
    "\n",
    "# git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install s3fs -q\n",
    "# !pip install tensorflow_hub -q\n",
    "# !pip install tensorflow_datasets -q\n",
    "# !pip install pycocotools -q\n",
    "# !pip install gin-config -q\n",
    "# !pip install immutabledict -q\n",
    "# !pip install sentencepiece -q\n",
    "# !pip install transformers -q\n",
    "# !pip install evaluate -q\n",
    "# !pip install sacrebleu -q\n",
    "# !pip install bert_score -q\n",
    "# !pip install sentence-transformers -q\n",
    "# !pip install keras-nlp -q\n",
    "# !pip install tensorflow-model-optimization -q\n",
    "# !pip install pyarrow fastparquet -q\n",
    "# !pip install -r official/projects/movinet/requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKl6v7VuSQnW",
    "outputId": "6f82bd89-480a-4f94-dd2c-8cf3866a32ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/.aws/credentials']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/ec2-user/.aws/credentials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials and S3 settings\n",
    "aws_access_key_id = config[\"default\"]['aws_access_key_id']\n",
    "aws_secret_access_key = config[\"default\"]['aws_secret_access_key']\n",
    "bucket_name = 'asl-capstone'\n",
    "s3_URI = 's3://asl-capstone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(key=aws_access_key_id, secret=aws_secret_access_key)\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3',aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key,\n",
    "                  region_name = 'us-west-2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E7UuTYQS75b_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 23:55:41.064230: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 23:55:41.767396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(2)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "# !export XLA_FLAGS=\"--xla_gpu_strict_conv_algorithm_picker=false --xla_gpu_force_compilation_parallelism=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386,
     "referenced_widgets": [
      "c8730bc225c448ed83d03c980411ec37",
      "9dd8f481e1de48429cbe8f3c41b3361c",
      "53f1249d01e44f1eb846b90a9ac3f21a",
      "8721eacce4b44913a798a82e44ca10a6",
      "08743108f461407d804357c0dbf6ded7",
      "8ce503ec21094870b987d9fef0c1364d",
      "63feb6f007894f8ba0554139e1d95ad9",
      "8185ffd3cdce4433ae54c559ab75cb57",
      "76f81bba35c74daaa131d293b74f16f6",
      "1dd59591368343d19923a0c5e0169bc0",
      "cc21a0b25944497a844d8a1fc36fcc5d",
      "ad51dcd5891e45cca9a290a9a744d28c",
      "113fe85010e74cb4b535157febf808e8",
      "0e0d36daeda3441791d3e7ca21a7b097",
      "bcd00e6c788f46aea761913b87c7331b",
      "5f52628b5aca41078df434e961292f4a",
      "d1a345df9d904996b2423960655673ff",
      "3e8b1c7ca5ed42ba80703728543a09c1",
      "5583644bec2d4be1a889338aede2859e",
      "3b73926262334455b671fa33d31eadd9",
      "775bb9dd303347dcadf0604b02d233b8",
      "7506923b6a8f4cffbe94dd9194d5ef78",
      "bdc0d514733c4e049429752530e10643",
      "2a410589229442c5a08b1e19aae62c23",
      "80d6ccb946c240cfbcb10a91f8c44c79",
      "ac7f8914736f4b5eaa1390537cc39d31",
      "67a00b046d254e0ab4473317c637059e",
      "5bccfe21423e4b65af8997a314e51921",
      "acf6a8e5f44c4638aeb38b6984a69ca8",
      "a17d3747768746bd9cc19a9bb07dd8f1",
      "41f196dea0004e958c91fc628c19c771",
      "d287c8fe184f41369fa597626cb1b12b",
      "d0669d9654564c049d9c0b28e6655c47",
      "244d17e04a4f41d285503960087ce67e",
      "098322ea0ed94efb946bffb6cbcfec25",
      "148c585f4ddf406681b05b1daf27227d",
      "c35c2d9a151d4e899fd935fd7c95a3b9",
      "6457a5ad2c5c465490a79036edd15c1f",
      "6f2bc280945e4521ac50a48302d55ee2",
      "a54bda6555174aad910291160a5741de",
      "4b951dfaf385457fadd2f1e1d2bc7785",
      "bb3d0d3d20dc47d39aef1798b0a4f637",
      "fe7f16ce9e774787a956d5a3fc77c7ed",
      "1e24e4a1f6564cb7aa61af39ce310283",
      "ccb7103fbd924eedb25f994580153855",
      "d79218f755c74875b5bcb07a9b1f0b54",
      "983815eaf4a5449e88dee260fc3cb986",
      "247b5875632a4134adc870e7e9b241ac",
      "119885c300d84755ae30152641ddc866",
      "eb525cc2161b4a668cf42f4397847ebe",
      "af517973c08c4bac83127ece0ea4964b",
      "ab3bf657fe1c47aeb9a05a5de0832f20",
      "0701ca98a52745a9a6981e0ec6b25d7d",
      "bcc438b1d54d4a2192fbf13d16723a67",
      "6c8fa39a797748db8d87444310adb049",
      "62383dac2ba2405d855b6bea35b0358a",
      "fa8f77c6ed7a40c68591f8843caef5a0",
      "64d82bcf90de412c85f03b5bf157c0d7",
      "ddabb3d36b794288bb3d8db94107c84a",
      "e2a7daa66f574bde9248fde4487d6c08",
      "0a28ab105a7647959914a094d68d9b5a",
      "67355b68cba847eba42038f9dce8b8ba",
      "70828d14ca154e80a0ebb08a44a4e270",
      "aa04001aa5994a94bb8bf4b05fb8d156",
      "46ec6504b7504b76959615555e610ddd",
      "1efebdbb775c4ba3b6b5d465b1605930",
      "4d580ef8885c4837b16566ac52929fb0",
      "bde961601a7f446ba7b5bb4e2fafbeaf",
      "2e39b5786e294d638372db2e143fc70a",
      "3d61cbf445824ae681019e743a97b8fe",
      "1b6fc395e4c14b95a9c2624a8d0aa211",
      "69eed7e8d4db4bf883ea69cf788cd5fe",
      "05fc3b60f8d141e996b22059c9a7ca09",
      "97749df1adfa4535b0d38aac2b028f02",
      "6285176e71c941d69d1b82cbbdcee879",
      "a09bca0d594942aa93f097a4ffa58c1d",
      "8d75ab215a4140b5b58ae71110ff187f"
     ]
    },
    "id": "16stFmLCqYFN",
    "outputId": "661b437a-cdf7-4ec2-e05a-7417578dd96b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tensorflow/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "2023-12-06 23:55:45.963956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:45.983018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:45.983825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:45.985146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:45.985885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:45.986593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:46.600443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:46.601410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:46.602155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 23:55:46.602893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20591 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "2023-12-06 23:55:48.073956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at deanna-emery/ASL_t5_movinet_sentence.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tft5_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " shared (Embedding)          multiple                  24674304  \n",
      "                                                                 \n",
      " encoder (TFT5MainLayer)     multiple                  109628544 \n",
      "                                                                 \n",
      " decoder (TFT5MainLayer)     multiple                  137949312 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222903552 (850.31 MB)\n",
      "Trainable params: 222903552 (850.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM, TFT5ForConditionalGeneration #, TFT5EncoderModel\n",
    "# from transformers.modeling_tf_outputs import TFBaseModelOutputWithPastAndCrossAttentions\n",
    "\n",
    "# with tf.device(\"/GPU:0\"):\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "# model = TFAutoModelForSeq2SeqLM.from_pretrained(\"deanna-emery/ASL_t5_word_epoch15_1204\")\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"deanna-emery/ASL_t5_movinet_sentence\")\n",
    "\n",
    "model.trainable = True\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"t5-large\")\n",
    "# model = TFT5ForConditionalGeneration.from_pretrained(\"t5-large\")\n",
    "# encoder_model = T5EncoderModel.from_pretrained(\"t5-large\")\n",
    "\n",
    "ENCODER_DIM = 768\n",
    "# ENCODER_DIM = 1024\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tft5_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " shared (Embedding)          multiple                  24674304  \n",
      "                                                                 \n",
      " encoder (TFT5MainLayer)     multiple                  109628544 \n",
      "                                                                 \n",
      " decoder (TFT5MainLayer)     multiple                  137949312 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222903552 (850.31 MB)\n",
      "Trainable params: 222903552 (850.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.trainable = True\n",
    "\n",
    "# for i in range(3):\n",
    "#     model.encoder.block[-(i+3)].trainable = False\n",
    "\n",
    "# for i in range(10):\n",
    "#     model.encoder.block[-(i+1)].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20404"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_files = fs.ls('s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/')\n",
    "s3_files = ['s3://' + file for file in s3_files]\n",
    "len(s3_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57672, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>path</th>\n",
       "      <th>movinet_path</th>\n",
       "      <th>caption_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello everyone!</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_0.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_0.npy</td>\n",
       "      <td>hello everyone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am Kelly Matthews,</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_1.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_1.npy</td>\n",
       "      <td>i am kelly matthews,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and I am the\\nResearch Coordinator</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_2.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_2.npy</td>\n",
       "      <td>and i am the research coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and Outreach Coordinator\\nat NCDHR.</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_3.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_3.npy</td>\n",
       "      <td>and outreach coordinator at ncdhr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My name is on that flyer</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_4.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_4.npy</td>\n",
       "      <td>my name is on that flyer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               caption  \\\n",
       "0                      Hello everyone!   \n",
       "1                 I am Kelly Matthews,   \n",
       "2   and I am the\\nResearch Coordinator   \n",
       "3  and Outreach Coordinator\\nat NCDHR.   \n",
       "4             My name is on that flyer   \n",
       "\n",
       "                                                                       path  \\\n",
       "0  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_0.npy   \n",
       "1  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_1.npy   \n",
       "2  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_2.npy   \n",
       "3  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_3.npy   \n",
       "4  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4fqpBXE0_Dc_4.npy   \n",
       "\n",
       "                                                                     movinet_path  \\\n",
       "0  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_0.npy   \n",
       "1  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_1.npy   \n",
       "2  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_2.npy   \n",
       "3  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_3.npy   \n",
       "4  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4fqpBXE0_Dc_4.npy   \n",
       "\n",
       "                      caption_cleaned  \n",
       "0                     hello everyone!  \n",
       "1                i am kelly matthews,  \n",
       "2   and i am the research coordinator  \n",
       "3  and outreach coordinator at ncdhr.  \n",
       "4            my name is on that flyer  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_files = pd.read_parquet(\"s3://asl-capstone/youtube-asl/1000-samples/masterfile_final.parquet\")\n",
    "\n",
    "# video_files = pd.read_parquet(\"s3://asl-capstone/youtube-asl/test_sample/numpy_files/RGB/masterfile.parquet\")\n",
    "video_files = video_files.drop_duplicates().reset_index(drop=True)\n",
    "video_files['movinet_path'] = video_files.path.str.replace(\"/numpy_files/\", '/movinet_embedding/')\n",
    "video_files['caption_cleaned'] = video_files.caption.str.lower().str.replace(r'\\[*\\]', ' ').str.replace('\\t',' ').str.replace('\\n',' ').str.replace('…', ' ').str.replace('–', ' ').str.replace('/', ' ').str.replace('*', ' ').str.replace('-', ' ').str.replace('  ',' ').str.replace('...',' ').str.replace('..','.').str.replace('??','?').str.replace('!!','!').str.replace('♪', '').str.replace('♫','').str.replace('#','').str.strip(' ')\n",
    "\n",
    "video_files = video_files[video_files['caption_cleaned']!='']\n",
    "video_files = video_files[video_files['caption_cleaned']!=' ']\n",
    "video_files = video_files[video_files['caption_cleaned']!='.']\n",
    "video_files = video_files[video_files['caption_cleaned']!='[demonstrates sign]']\n",
    "video_files = video_files[video_files['caption_cleaned']!='[music]']\n",
    "video_files = video_files[video_files['caption_cleaned']!='(music)']\n",
    "video_files = video_files[video_files['caption_cleaned']!='captioned by www.aslcaptions.com']\n",
    "video_files = video_files[video_files['caption_cleaned']!='captioned by aslcaptions.com']\n",
    "# video_files = video_files[video_files['caption_cleaned'].str.contains('&')==False]\n",
    "# video_files = video_files[video_files['caption_cleaned'].str.contains('www.')==False]\n",
    "\n",
    "video_files = video_files.dropna(subset=['caption_cleaned'])\n",
    "\n",
    "video_files = video_files.groupby(\"caption_cleaned\").head(5)\n",
    "\n",
    "print(video_files.shape)\n",
    "video_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>path</th>\n",
       "      <th>movinet_path</th>\n",
       "      <th>caption_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Sign with me!</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_2.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_2.npy</td>\n",
       "      <td>sign with me!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Number</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_3.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_3.npy</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Number 1</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_4.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_4.npy</td>\n",
       "      <td>number 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Number 2</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_5.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_5.npy</td>\n",
       "      <td>number 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Number 3</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_6.npy</td>\n",
       "      <td>s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_6.npy</td>\n",
       "      <td>number 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           caption  \\\n",
       "270  Sign with me!   \n",
       "271         Number   \n",
       "272       Number 1   \n",
       "273       Number 2   \n",
       "274       Number 3   \n",
       "\n",
       "                                                                         path  \\\n",
       "270  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_2.npy   \n",
       "271  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_3.npy   \n",
       "272  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_4.npy   \n",
       "273  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_5.npy   \n",
       "274  s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_6.npy   \n",
       "\n",
       "                                                                       movinet_path  \\\n",
       "270  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_2.npy   \n",
       "271  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_3.npy   \n",
       "272  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_4.npy   \n",
       "273  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_5.npy   \n",
       "274  s3://asl-capstone/youtube-asl/1000-samples/movinet_embedding/4zPLsd-C7cI_6.npy   \n",
       "\n",
       "    caption_cleaned  \n",
       "270   sign with me!  \n",
       "271          number  \n",
       "272        number 1  \n",
       "273        number 2  \n",
       "274        number 3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_files = video_files[video_files['movinet_path'].isin(s3_files)]\n",
    "n_files = len(video_files)\n",
    "print(n_files)\n",
    "video_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# video_files[(video_files['caption_cleaned'].str.len() > 40) & (video_files['caption_cleaned'].str.len() < 60)].caption_cleaned.unique()\n",
    "\n",
    "video_files['caption_cleaned'].str.len().hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start at training mini model to convert from to correct shape for T5\n",
    "# # Loss function: CosineSimilarity.\n",
    "# # Minimize for cosine sim between avg label emb and avg vid emb (after flattening)?\n",
    "# vid_labels = tokenizer(video_files['caption_cleaned'].to_list(), return_tensors=\"tf\", padding=True)\n",
    "# label_embeds = model.encoder.embed_tokens(vid_labels.input_ids)\n",
    "# label_embeds_avg = tf.math.reduce_mean(label_embeds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15996, 4)\n",
      "(3600, 4)\n",
      "(400, 4)\n"
     ]
    }
   ],
   "source": [
    "train_files, test_files = train_test_split(video_files, train_size=0.8, random_state=210)\n",
    "test_files, val_files = train_test_split(test_files, train_size=0.9, random_state=210)\n",
    "\n",
    "# train_files = train_files.sample(10)\n",
    "# test_files = test_files.sample(10)\n",
    "# val_files = val_files.sample(16)\n",
    "\n",
    "\n",
    "\n",
    "print(train_files.shape)\n",
    "print(test_files.shape)\n",
    "print(val_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(file_paths_df, n_frames=256, max_tokens=128):\n",
    "    for _, row in file_paths_df.iterrows():\n",
    "        # try:\n",
    "        with fs.open(row['movinet_path'], 'rb') as f:\n",
    "            vid_embedding = np.load(f)[0] #.astype(np.float16)\n",
    "\n",
    "        if vid_embedding.shape[0] == 0:\n",
    "            print(row['movinet_path'])\n",
    "            fs.rm(row['movinet_path'])\n",
    "            pass\n",
    "\n",
    "        \n",
    "        if vid_embedding.shape[0] < n_frames:\n",
    "            # for shorter frame lengths, pad with zeros\n",
    "            padding = tf.zeros((tf.constant(n_frames) - vid_embedding.shape[0], \n",
    "                                vid_embedding.shape[1]))\n",
    "            \n",
    "            attention_mask = tf.concat([tf.ones(vid_embedding.shape[0]), \n",
    "                                        tf.zeros(tf.constant(n_frames) - vid_embedding.shape[0])], \n",
    "                                       axis=0)\n",
    "            \n",
    "            vid_embedding = tf.concat([vid_embedding, padding], axis=0)\n",
    "            \n",
    "        else:\n",
    "            # for exactly right size, just output attention_mask\n",
    "            vid_embedding = vid_embedding[:n_frames]\n",
    "            attention_mask = tf.ones(vid_embedding.shape[0])\n",
    "            \n",
    "        # elif vid_embedding.shape[0] > n_frames:\n",
    "        #     # for longer frame lengths, interpolate\n",
    "        #     vid_embedding = vid_embedding[:n_frames]\n",
    "        #     attention_mask = tf.ones(vid_embedding.shape[0])\n",
    "        \n",
    "        \n",
    "        label = tokenizer(row['caption_cleaned'], return_tensors=\"tf\", \n",
    "                           padding='max_length', max_length=max_tokens, truncation=True).input_ids[0]\n",
    "        # label = row['caption']\n",
    "        \n",
    "        yield {'inputs_embeds':vid_embedding, #'input_ids':None, 'training':True,\n",
    "               'attention_mask':attention_mask, 'labels':label}\n",
    "        # except:\n",
    "        #     print(vid_embedding.shape, row['movinet_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create TensorFlow Dataset for model input. \n",
    "N_FRAMES = 320\n",
    "MAX_TOKENS = 128\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: data_generator(train_files, n_frames=N_FRAMES),\n",
    "    output_signature=({'inputs_embeds':tf.TensorSpec(shape=(N_FRAMES, ENCODER_DIM), dtype=tf.float32),\n",
    "                       'attention_mask':tf.TensorSpec(shape=(N_FRAMES), dtype=tf.float32), \n",
    "                       'labels':tf.TensorSpec(shape=(MAX_TOKENS), dtype=tf.int32)}\n",
    "                       ))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: data_generator(test_files, n_frames=N_FRAMES),\n",
    "    output_signature=({'inputs_embeds':tf.TensorSpec(shape=(N_FRAMES, ENCODER_DIM), dtype=tf.float32),\n",
    "                       'attention_mask':tf.TensorSpec(shape=(N_FRAMES), dtype=tf.float32), \n",
    "                       'labels':tf.TensorSpec(shape=(MAX_TOKENS), dtype=tf.int32)}\n",
    "                       ))\n",
    "\n",
    "eval_dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: data_generator(val_files, n_frames=N_FRAMES),\n",
    "    output_signature=({'inputs_embeds':tf.TensorSpec(shape=(N_FRAMES, ENCODER_DIM), dtype=tf.float32),\n",
    "                       'attention_mask':tf.TensorSpec(shape=(N_FRAMES), dtype=tf.float32), \n",
    "                       'labels':tf.TensorSpec(shape=(MAX_TOKENS), dtype=tf.int32)}\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No label_cols specified for KerasMetricCallback, assuming you want the 'labels' key.\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# push_to_hub_callback = PushToHubCallback(\n",
    "#     output_dir=\"./t5_movinet_word\", tokenizer=tokenizer, hub_model_id=\"deanna-emery/ASL_t5_movinet\"\n",
    "# )\n",
    "\n",
    "\n",
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "# bertscore = evaluate.load(\"bertscore\",device=\"cpu\")\n",
    "# st_sim = SentenceTransformer('all-mpnet-base-v2',device=\"cpu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    # Decode tokens to words\n",
    "    preds = np.where(preds >= 0, preds, tokenizer.pad_token_id)\n",
    "    labels = np.where(labels >= 0, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    try:\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "        # # Create SentenceTransformer embeddings from words\n",
    "        # st_preds = st_sim.encode(decoded_preds)\n",
    "        # st_labels = st_sim.encode(decoded_labels)\n",
    "    \n",
    "        # # Calculate cosine similarity\n",
    "        # cos_sim = []\n",
    "        # for p, l in zip(st_preds, st_labels):\n",
    "        #     cos_sim.append(float(util.cos_sim(p, l)))\n",
    "    \n",
    "        # Calculate BLEU and BERT score\n",
    "        result_1 = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        # result_2 = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\", device=\"cpu\")\n",
    "    \n",
    "        # Store results to dcit\n",
    "        result = {\"bleu\": result_1[\"score\"]}\n",
    "        # result['avg_bertscore_f1'] = np.mean(result_2['f1'])\n",
    "        # result['avg_sent_trans_sim'] = np.median(cos_sim)\n",
    "    \n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "        return result\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, \n",
    "                                      eval_dataset=eval_dataset.batch(24, drop_remainder=True),\n",
    "                                      batch_size=24,\n",
    "                                      predict_with_generate=True,\n",
    "                                      generate_kwargs={'max_new_tokens':128, \n",
    "                                                       'temperature':0.01,\n",
    "                                                       'no_repeat_ngram_size':2,\n",
    "                                                          'do_sample':True,\n",
    "                                                          'top_k':50, \n",
    "                                                          'top_p':0.90,\n",
    "                                                          # 'early_stopping':True,\n",
    "                                                      }\n",
    "                                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIGURE OUT OPTIMIZER FOR t5\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 24\n",
    "VAL_BATCH_SIZE = 24\n",
    "\n",
    "train_steps = len(train_files) // BATCH_SIZE\n",
    "total_train_steps = train_steps * NUM_EPOCHS\n",
    "\n",
    "test_steps = len(test_files) // VAL_BATCH_SIZE\n",
    "\n",
    "# Set learning rate scheduler, optimizer, and loss function\n",
    "initial_learning_rate = 5e-4\n",
    "learning_rate = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps=total_train_steps, warmup_target=5e-4, warmup_steps=600\n",
    ")\n",
    "# learning_rate = 1e-4\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adafactor(learning_rate=learning_rate)\n",
    "\n",
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                from_logits=True)\n",
    "\n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1, name='top_1'), \n",
    "           tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5') ]\n",
    "\n",
    "model.compile(optimizer=optimizer, metrics=metrics) \n",
    "#loss=model.hf_compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def visualize_lr_schedule(opt, n_steps, step_s) -> Tuple[List[int], List[float]]:\n",
    "    \"\"\"Visualize tensorflow keras scheduler learning rate over the course of n_steps training steps.\n",
    "\n",
    "    Args:\n",
    "        opt (LearningRateSchedule): learning rate scheduler to be visualized.\n",
    "        n_steps (int): number of training steps to visualize over.\n",
    "        step_s (int): sampling step of the training steps, i.e. takes each step_s in the interval [0, n_steps].\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[int], List[float]]: returns x (steps), y (lr values) values of the plot.\n",
    "    \"\"\"\n",
    "    lr = []\n",
    "    steps = list(range(0, n_steps, step_s))\n",
    "\n",
    "    for step in steps:\n",
    "        lr_at_s = opt(step).numpy()\n",
    "        lr.append(lr_at_s)\n",
    "\n",
    "    plt.suptitle(f'Learning rate schedule of {type(opt).__name__}')\n",
    "    plt.plot(steps, lr)\n",
    "\n",
    "    return steps, lr\n",
    "\n",
    "\n",
    "steps, lr_values = visualize_lr_schedule(learning_rate, n_steps=total_train_steps, step_s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    666/Unknown - 1949s 3s/step - loss: 0.2351 - top_1: 0.9496 - top_5: 0.9736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 05:24:07.111344: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16830050142986932903\n",
      "2023-12-07 05:24:07.111384: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16197297226241811907\n",
      "2023-12-07 05:24:07.111394: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2122708291111646090\n",
      "2023-12-07 05:24:07.111402: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16003037537626211462\n",
      "2023-12-07 05:24:07.111641: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 15883464981596239054\n",
      "2023-12-07 05:30:17.550720: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 139084017581381676\n",
      "2023-12-07 05:30:17.550767: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 8335142302242855362\n",
      "2023-12-07 05:30:17.550772: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 16213043074485490244\n",
      "2023-12-07 05:30:17.550777: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 2495272887379571151\n",
      "2023-12-07 05:30:17.550781: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 10006890578140463519\n",
      "2023-12-07 05:30:17.550785: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 2985461049459602583\n",
      "2023-12-07 05:30:17.550789: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 16672458785430214245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 2493s 4s/step - loss: 0.2351 - top_1: 0.9496 - top_5: 0.9736 - val_loss: 0.3181 - val_top_1: 0.9413 - val_top_5: 0.9640 - bleu: 1.1898 - gen_len: 13.0052\n",
      "Epoch 2/5\n",
      "666/666 [==============================] - 2519s 4s/step - loss: 0.2173 - top_1: 0.9522 - top_5: 0.9760 - val_loss: 0.3255 - val_top_1: 0.9409 - val_top_5: 0.9638 - bleu: 1.5250 - gen_len: 13.0182\n",
      "Epoch 3/5\n",
      "666/666 [==============================] - 2755s 4s/step - loss: 0.1965 - top_1: 0.9554 - top_5: 0.9789 - val_loss: 0.3372 - val_top_1: 0.9405 - val_top_5: 0.9630 - bleu: 1.4326 - gen_len: 13.8776\n",
      "Epoch 4/5\n",
      "666/666 [==============================] - 2576s 4s/step - loss: 0.1776 - top_1: 0.9586 - top_5: 0.9815 - val_loss: 0.3415 - val_top_1: 0.9408 - val_top_5: 0.9633 - bleu: 1.9840 - gen_len: 12.7656\n",
      "Epoch 5/5\n",
      "666/666 [==============================] - ETA: 0s - loss: 0.1642 - top_1: 0.9610 - top_5: 0.9834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 08:23:12.929632: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Attempting to slice scalar input.\n",
      "2023-12-07 08:23:12.930187: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: InvalidArgumentError: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [24,1,1] != values[1].shape = [] [Op:Pack] name: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/tmp/ipykernel_26535/4162970636.py\", line 15, in data_generator\n",
      "    padding = tf.zeros((tf.constant(n_frames) - vid_embedding.shape[0],\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [24,1,1] != values[1].shape = [] [Op:Pack] name: \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'decoder' (type TFT5MainLayer).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} Attempting to slice scalar input. [Op:StridedSlice] name: tft5_for_conditional_generation/decoder/strided_slice/\n\nCall arguments received by layer 'decoder' (type TFT5MainLayer):\n  • input_ids=tf.Tensor(shape=(24, 1), dtype=int32)\n  • attention_mask=None\n  • encoder_hidden_states=tf.Tensor(shape=(24, 320, 768), dtype=float32)\n  • encoder_attention_mask=tf.Tensor(shape=(24, 320), dtype=int32)\n  • inputs_embeds=None\n  • head_mask=None\n  • encoder_head_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/keras_callbacks.py:227\u001b[0m, in \u001b[0;36mKerasMetricCallback.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_function(generation_inputs, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict_on_batch(batch)\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/generation/tf_utils.py:949\u001b[0m, in \u001b[0;36mTFGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, seed, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m    942\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    943\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m    944\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_beams \u001b[38;5;241m<\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/generation/tf_utils.py:2019\u001b[0m, in \u001b[0;36mTFGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, logits_warper, max_length, pad_token_id, eos_token_id, seed, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[1;32m   2015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated, finished_sequences, cur_len, model_kwargs\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;66;03m# 5. run generation\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;66;03m# 1st generation step has to be run before to initialize `past_key_values`\u001b[39;00m\n\u001b[0;32m-> 2019\u001b[0m generated, finished_sequences, cur_len, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43msample_body_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinished_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;66;03m# 2-to-n generation steps can then be run in autoregressive fashion\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# only in case 1st generation step does NOT yield EOS token though\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m maximum_iterations \u001b[38;5;241m=\u001b[39m max_length \u001b[38;5;241m-\u001b[39m cur_len\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/generation/tf_utils.py:1937\u001b[0m, in \u001b[0;36mTFGenerationMixin.sample.<locals>.sample_body_fn\u001b[0;34m(generated, finished_sequences, cur_len, model_kwargs)\u001b[0m\n\u001b[1;32m   1935\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, use_cache\u001b[38;5;241m=\u001b[39muse_cache, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;66;03m# forward pass to get next token logits\u001b[39;00m\n\u001b[0;32m-> 1937\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m model_outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1945\u001b[0m \u001b[38;5;66;03m# pre-process distribution\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/models/t5/modeling_tf_t5.py:1358\u001b[0m, in \u001b[0;36mTFT5ForConditionalGeneration.call\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     decoder_input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shift_right(labels)\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1358\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# T5v1.1 does not tie output word embeddings and thus does not require downscaling\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/transformers/models/t5/modeling_tf_t5.py:727\u001b[0m, in \u001b[0;36mTFT5MainLayer.call\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, encoder_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    722\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mless_equal(\n\u001b[1;32m    723\u001b[0m     tf\u001b[38;5;241m.\u001b[39mtile(seq_ids[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :], (batch_size, mask_seq_length, \u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m    724\u001b[0m     seq_ids[\u001b[38;5;28;01mNone\u001b[39;00m, :, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m    725\u001b[0m )\n\u001b[1;32m    726\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(causal_mask, dtype\u001b[38;5;241m=\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 727\u001b[0m extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m attention_mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     extended_attention_mask \u001b[38;5;241m=\u001b[39m extended_attention_mask[:, :, \u001b[38;5;241m-\u001b[39mseq_length:, :]\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'decoder' (type TFT5MainLayer).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} Attempting to slice scalar input. [Op:StridedSlice] name: tft5_for_conditional_generation/decoder/strided_slice/\n\nCall arguments received by layer 'decoder' (type TFT5MainLayer):\n  • input_ids=tf.Tensor(shape=(24, 1), dtype=int32)\n  • attention_mask=None\n  • encoder_hidden_states=tf.Tensor(shape=(24, 320, 768), dtype=float32)\n  • encoder_attention_mask=tf.Tensor(shape=(24, 320), dtype=int32)\n  • inputs_embeds=None\n  • head_mask=None\n  • encoder_head_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# with tf.device(\"/GPU:0\"):\n",
    "history = model.fit(train_dataset.batch(BATCH_SIZE,drop_remainder=True), \n",
    "                    validation_data=test_dataset.batch(VAL_BATCH_SIZE,drop_remainder=True),\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    validation_batch_size = VAL_BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    # predict_with_generate = True,\n",
    "                    # steps_per_epoch=train_steps,\n",
    "                    # validation_steps=test_steps,\n",
    "                    callbacks=[metric_callback],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 08:26:40.931058: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: InvalidArgumentError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [11,11] [Op:Fill] name: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/tmp/ipykernel_26535/4162970636.py\", line 19, in data_generator\n",
      "    tf.zeros(tf.constant(n_frames) - vid_embedding.shape[0])],\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [11,11] [Op:Fill] name: \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} InvalidArgumentError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [11,11] [Op:Fill] name: \nTraceback (most recent call last):\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_26535/4162970636.py\", line 19, in data_generator\n    tf.zeros(tf.constant(n_frames) - vid_embedding.shape[0])],\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [11,11] [Op:Fill] name: \n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m24\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         test_outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(inputs_embeds \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      7\u001b[0m                                       attention_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],  \n\u001b[1;32m      8\u001b[0m                                       max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                       \u001b[38;5;66;03m# early_stopping=True,\u001b[39;00m\n\u001b[1;32m     16\u001b[0m                                      ) \n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:814\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    813\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:777\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 777\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3028\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3028\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3029\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3030\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   6655\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6656\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} InvalidArgumentError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [11,11] [Op:Fill] name: \nTraceback (most recent call last):\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_26535/4162970636.py\", line 19, in data_generator\n    tf.zeros(tf.constant(n_frames) - vid_embedding.shape[0])],\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [11,11] [Op:Fill] name: \n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for batch in test_dataset.batch(24):\n",
    "    try:\n",
    "        test_outputs = model.generate(inputs_embeds = batch['inputs_embeds'], \n",
    "                                      attention_mask=batch['attention_mask'],  \n",
    "                                      max_new_tokens=128, \n",
    "                                      temperature=0.01,\n",
    "                                      # num_beams=2, \n",
    "                                      no_repeat_ngram_size=2,\n",
    "                                      do_sample=True,\n",
    "                                      top_k=50, \n",
    "                                      top_p=0.90, # try 0.5 and 0.2\n",
    "                                      # early_stopping=True,\n",
    "                                     ) \n",
    "    \n",
    "        pred = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)\n",
    "        label = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "    \n",
    "        predictions += pred\n",
    "        labels += label\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in eval_dataset.batch(24):\n",
    "    try:\n",
    "        test_outputs = model.generate(inputs_embeds = batch['inputs_embeds'], \n",
    "                                      attention_mask=batch['attention_mask'],  \n",
    "                                      max_new_tokens=128, \n",
    "                                      temperature=0.01,\n",
    "                                      # num_beams=2, \n",
    "                                      no_repeat_ngram_size=2,\n",
    "                                      do_sample=True,\n",
    "                                      top_k=50, \n",
    "                                      top_p=0.90, # try 0.5 and 0.2\n",
    "                                      # early_stopping=True,\n",
    "                                     ) \n",
    "    \n",
    "        pred = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)\n",
    "        label = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "    \n",
    "        predictions += pred\n",
    "        labels += label\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_standard = evaluate.load('bleu')\n",
    "st_sim = SentenceTransformer('all-mpnet-base-v2',device=\"cpu\")\n",
    "# bertscore = evaluate.load(\"bertscore\",device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_standard_metric = bleu_standard.compute(predictions=predictions, references=labels)\n",
    "bleu_metric = bleu.compute(predictions=predictions, references=labels)\n",
    "# bertscore_metric = bertscore.compute(predictions=predictions, references=labels, lang=\"en\", device=\"cpu\")\n",
    "\n",
    "# Create SentenceTransformer embeddings from words\n",
    "st_preds = st_sim.encode(predictions)\n",
    "st_labels = st_sim.encode(labels)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cos_sim = []\n",
    "for p, l in zip(st_preds, st_labels):\n",
    "    cos_sim.append(float(util.cos_sim(p, l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Standard\n",
      "{'bleu': 0.01527910090664875, 'precisions': [0.14048839312631897, 0.017055048969942588, 0.006277344493056876, 0.003907097894508357], 'brevity_penalty': 0.9813340795367348, 'length_ratio': 0.9815061399615328, 'translation_length': 6634, 'reference_length': 6759}\n",
      "SacreBLEU\n",
      "{'score': 1.5279100906648755, 'counts': [932, 101, 33, 18], 'totals': [6634, 5922, 5257, 4607], 'precisions': [14.048839312631896, 1.7055048969942588, 0.6277344493056877, 0.3907097894508357], 'bp': 0.9813340795367348, 'sys_len': 6634, 'ref_len': 6759}\n",
      "Mean ST cosine sim\n",
      "0.20208033932114344\n"
     ]
    }
   ],
   "source": [
    "print('BLEU Standard')\n",
    "print(bleu_standard_metric)\n",
    "print('SacreBLEU')\n",
    "print(bleu_metric)\n",
    "# print('Mean BERTScore')\n",
    "# print(np.mean(bertscore_metric['f1']))\n",
    "print(\"Mean ST cosine sim\")\n",
    "print(np.mean(cos_sim))\n",
    "\n",
    "######## 11351 datapoints\n",
    "# BLEU Standard\n",
    "# {'bleu': 0.0055599118181396245, 'precisions': [0.12159820609519927, 0.007017947537965945, 0.00164354743277891, 0.0009946442234123947], 'brevity_penalty': 0.9097479392501068, 'length_ratio': 0.9135859949715989, 'translation_length': 19622, 'reference_length': 21478}\n",
    "# SacreBLEU\n",
    "# {'score': 0.5559911818139627, 'counts': [2386, 122, 25, 13], 'totals': [19622, 17384, 15211, 13070], 'precisions': [12.159820609519926, 0.7017947537965946, 0.164354743277891, 0.09946442234123948], 'bp': 0.9097479392501068, 'sys_len': 19622, 'ref_len': 21478}\n",
    "# Mean BERTScore\n",
    "# 0.842458401358053\n",
    "# Mean ST cosine sim\n",
    "# 0.14556280111952166\n",
    "\n",
    "######## 13378 datapoints\n",
    "# BLEU Standard\n",
    "# {'bleu': 0.009477871726519475, 'precisions': [0.12432853250291942, 0.009819682815555073, 0.003377882214715817, 0.0019567283501984683], 'brevity_penalty': 1.0, 'length_ratio': 1.0152946290953642, 'translation_length': 25690, 'reference_length': 25303}\n",
    "# SacreBLEU\n",
    "# {'score': 0.9477871726519478, 'counts': [3194, 226, 69, 35], 'totals': [25690, 23015, 20427, 17887], 'precisions': [12.432853250291942, 0.9819682815555073, 0.3377882214715817, 0.1956728350198468], 'bp': 1.0, 'sys_len': 25690, 'ref_len': 25303}\n",
    "# Mean BERTScore\n",
    "# 0.8448950230897097\n",
    "# Mean ST cosine sim\n",
    "# 0.1621186593375244\n",
    "\n",
    "######## 19996 datapoints, 5 epochs\n",
    "# BLEU Standard\n",
    "# {'bleu': 0.012806860474137838, 'precisions': [0.13494694960212203, 0.013957509881422924, 0.0054226918798665185, 0.0026902990979585377], 'brevity_penalty': 0.9947090070850595, 'length_ratio': 0.9947229551451188, 'translation_length': 9048, 'reference_length': 9096}\n",
    "# SacreBLEU\n",
    "# {'score': 1.280686047413783, 'counts': [1221, 113, 39, 17], 'totals': [9048, 8096, 7192, 6319], 'precisions': [13.494694960212202, 1.3957509881422925, 0.5422691879866518, 0.2690299097958538], 'bp': 0.9947090070850593, 'sys_len': 9048, 'ref_len': 9096}\n",
    "# Mean ST cosine sim\n",
    "# 0.19157156346736579\n",
    "\n",
    "######## 19996 datapoints, 10 epochs\n",
    "# BLEU Standard\n",
    "# {'bleu': 0.01527910090664875, 'precisions': [0.14048839312631897, 0.017055048969942588, 0.006277344493056876, 0.003907097894508357], 'brevity_penalty': 0.9813340795367348, 'length_ratio': 0.9815061399615328, 'translation_length': 6634, 'reference_length': 6759}\n",
    "# SacreBLEU\n",
    "# {'score': 1.5279100906648755, 'counts': [932, 101, 33, 18], 'totals': [6634, 5922, 5257, 4607], 'precisions': [14.048839312631896, 1.7055048969942588, 0.6277344493056877, 0.3907097894508357], 'bp': 0.9813340795367348, 'sys_len': 6634, 'ref_len': 6759}\n",
    "# Mean ST cosine sim\n",
    "# 0.20208033932114344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  2. camp responsibilities &amp; duties :\n",
      "label:  1. fundraising coordinator\n",
      " \n",
      "prediction:  i am currently living in california.\n",
      "label:  you can see all the deep details hidden and explore\n",
      " \n",
      "prediction:  my friends,\n",
      "label:  i really look forward to!\n",
      " \n",
      "prediction:  i'm going to show you how to do it.\n",
      "label:  and you can turn student feedback off,\n",
      " \n",
      "prediction:  hello! i'm rogan and welcome.\n",
      "label:  i'm jethro wooddall.\n",
      " \n",
      "prediction:  or a conjunction\n",
      "label:  dentures washington his wood? no\n",
      " \n",
      "prediction:  my dog (who is my mom)\n",
      "label:  you want save planet (way can do it)\n",
      " \n",
      "prediction:  and what happens when a child is placed in  foster care\n",
      "label:  to be involved in big brothers big sisters.\n",
      " \n",
      "prediction:  i’m a big advocate for deaf rights.\n",
      "label:  join us\n",
      " \n",
      "prediction:  at this point, he is unable to provide any educational opportunities for his students.\n",
      "label:  but today, i want to focus mainly on illinois school for the deaf,\n",
      " \n",
      "prediction:  go for it!\n",
      "label:  that would show that i can do it\n",
      " \n",
      "prediction:  the u.s. military said it is investigating a \"hidden gem\"\n",
      "label:  from the spine to the muscles at the back of the head.\n",
      " \n",
      "prediction:  coronavirus, covid 19, co conoc 19, and colina 19, all have coronal antibodies\n",
      "label:  winter of 2019, not in the year 2020.\n",
      " \n",
      "prediction:  but he tells them to come and go.\n",
      "label:  he’s been through trial after trial, false accusations,\n",
      " \n",
      "prediction:  police say the man was wearing a black hat with an orange shirt.\n",
      "label:  but just before graduation, he was admitted to the hospital with heart failure, so his\n",
      " \n",
      "prediction:  the other man was shot in the back\n",
      "label:  images show a large fire on the side of an oil tanker,\n",
      " \n",
      "prediction:  he’s a god who blesses his enemies.\n",
      "label:  are living righteous lives, and that the poor, sick, and needy are suffering\n",
      " \n",
      "prediction:  he even called the senate and house leaders to express concern about the future of the united states.\n",
      "label:  it is dangerous and it is the latest health concern for people living on the big island.\n",
      " \n",
      "prediction:  even his plan to kill him was a disaster.\n",
      "label:  they say the men all have to be circumcised.\n",
      " \n",
      "prediction:  i'm a deaf bing.\n",
      "label:  it's impossible!\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(20,40):\n",
    "    print('prediction: ', predictions[i])\n",
    "    print('label: ', labels[i])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5048086359175662"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19996"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>prediction</th>\n",
       "      <th>st_cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we have a sad update to the story of the chicago woman was killed when her baby was cut from</td>\n",
       "      <td>the senate voted to confirm the resolution and set the record straight at 7 2</td>\n",
       "      <td>0.141476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we also updated the irid website</td>\n",
       "      <td>we've raised funds to fund events and initiatives that are specific to our membership.</td>\n",
       "      <td>0.247976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she discussed the team's fight for equal pay and said</td>\n",
       "      <td>adams said he did not think if trump did,</td>\n",
       "      <td>0.202298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and bombings spanning three countries.</td>\n",
       "      <td>police say he was assaulted by a group of people who claimed christianity.</td>\n",
       "      <td>0.174588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>those techniques, including waterboarding, have been described by many as torture.</td>\n",
       "      <td>the senate and fda are proposing tougher sentences for those accused of</td>\n",
       "      <td>0.280446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>really, i am still uncertain of the efficiency of this program that was implemented</td>\n",
       "      <td>i am excited to share this video with you today.</td>\n",
       "      <td>0.088498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>over time, qabil's personality became more</td>\n",
       "      <td>qabil is adam's twin sister.</td>\n",
       "      <td>0.572011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>his power to smear him.</td>\n",
       "      <td>four months ago, a cat named yvonne swann came to the rescue.</td>\n",
       "      <td>-0.005715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>remember</td>\n",
       "      <td>eat</td>\n",
       "      <td>0.225695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>yes, yes. we all know of the ongoing issues,</td>\n",
       "      <td>what is the best way to improve the teaching style?</td>\n",
       "      <td>-0.013180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          caption  \\\n",
       "0    we have a sad update to the story of the chicago woman was killed when her baby was cut from   \n",
       "1                                                                we also updated the irid website   \n",
       "2                                           she discussed the team's fight for equal pay and said   \n",
       "3                                                          and bombings spanning three countries.   \n",
       "4              those techniques, including waterboarding, have been described by many as torture.   \n",
       "..                                                                                            ...   \n",
       "707           really, i am still uncertain of the efficiency of this program that was implemented   \n",
       "708                                                    over time, qabil's personality became more   \n",
       "709                                                                       his power to smear him.   \n",
       "710                                                                                      remember   \n",
       "711                                                  yes, yes. we all know of the ongoing issues,   \n",
       "\n",
       "                                                                                 prediction  \\\n",
       "0             the senate voted to confirm the resolution and set the record straight at 7 2   \n",
       "1    we've raised funds to fund events and initiatives that are specific to our membership.   \n",
       "2                                                 adams said he did not think if trump did,   \n",
       "3                police say he was assaulted by a group of people who claimed christianity.   \n",
       "4                   the senate and fda are proposing tougher sentences for those accused of   \n",
       "..                                                                                      ...   \n",
       "707                                        i am excited to share this video with you today.   \n",
       "708                                                            qabil is adam's twin sister.   \n",
       "709                           four months ago, a cat named yvonne swann came to the rescue.   \n",
       "710                                                                                     eat   \n",
       "711                                     what is the best way to improve the teaching style?   \n",
       "\n",
       "     st_cos_sim  \n",
       "0      0.141476  \n",
       "1      0.247976  \n",
       "2      0.202298  \n",
       "3      0.174588  \n",
       "4      0.280446  \n",
       "..          ...  \n",
       "707    0.088498  \n",
       "708    0.572011  \n",
       "709   -0.005715  \n",
       "710    0.225695  \n",
       "711   -0.013180  \n",
       "\n",
       "[712 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pred = pd.DataFrame({'caption':labels, 'prediction':predictions, \n",
    "                          'st_cos_sim':cos_sim})\n",
    "word_pred.to_parquet(f\"s3://asl-capstone/t5_movinet_sent_epoch10_{n_files}.parquet\")\n",
    "word_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>prediction</th>\n",
       "      <th>st_cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>praise the lord</td>\n",
       "      <td>praise the lord</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>fox</td>\n",
       "      <td>fox</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>delicious</td>\n",
       "      <td>delicious</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>rainbows rainbows high up in the sky,</td>\n",
       "      <td>rainbows rainbow high up in the sky.</td>\n",
       "      <td>0.970885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>a d grade</td>\n",
       "      <td>a c grade</td>\n",
       "      <td>0.920364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>scrub your hands for at least 20 seconds.</td>\n",
       "      <td>dry your hands using a clean towel.</td>\n",
       "      <td>0.894355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>school performances for deaf children</td>\n",
       "      <td>encouraging deaf performers to participate.</td>\n",
       "      <td>0.863475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>raindrops, raindrops falling to the ground.</td>\n",
       "      <td>raindrops.</td>\n",
       "      <td>0.833784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>he called himself, \"i am\"</td>\n",
       "      <td>jesus called himself, \"i am\"</td>\n",
       "      <td>0.830660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>a radical life of discipleship to those around him!</td>\n",
       "      <td>a radical life of obedience to god.</td>\n",
       "      <td>0.824819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>0.818956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>welcome to sign1news.</td>\n",
       "      <td>sign1news.</td>\n",
       "      <td>0.817963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>you are my sunshine my only&amp;nbsp; sunshine</td>\n",
       "      <td>you are my sunshine</td>\n",
       "      <td>0.810030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>welcome to sign1news.</td>\n",
       "      <td>thank you for watching sign1news.</td>\n",
       "      <td>0.796849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>baby and dad!</td>\n",
       "      <td>baby and boy!</td>\n",
       "      <td>0.755276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>my second asl professor's name was will white.</td>\n",
       "      <td>my second asl professor's name was robert sanderson.</td>\n",
       "      <td>0.745749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>again, the number is (866) 246 0133</td>\n",
       "      <td>the phone number is: +61 866 328 8933</td>\n",
       "      <td>0.740335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>snowflake, right? slowly, slowly. right?</td>\n",
       "      <td>snowflakes snowflake?</td>\n",
       "      <td>0.699171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>pink</td>\n",
       "      <td>white</td>\n",
       "      <td>0.651829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>the interpreting and deaf communities may look at these messages, empathize with their similar experiences,</td>\n",
       "      <td>social media has become a tool of empowerment for deaf people.</td>\n",
       "      <td>0.627510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>n: it's hot, we've been out at sea for so long.</td>\n",
       "      <td>a: i miss fish. m: it's too fast.</td>\n",
       "      <td>0.623841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>language delays are from a lack of exposure to early language development.</td>\n",
       "      <td>language deprivation is when a child is unable to understand spoken language.</td>\n",
       "      <td>0.618356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the boy gets sad when he realizes his gum is no longer there</td>\n",
       "      <td>the little boy sees a bench where he puts his gum</td>\n",
       "      <td>0.615374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>see that? i sign what's west and east for me, not for you.</td>\n",
       "      <td>if you're going to be the \"right\" direction, you sign as you would see it. you go right.</td>\n",
       "      <td>0.591377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>the deaf studies department emailed me the application forms and instructions.</td>\n",
       "      <td>so i asked them to help me with my application and if they would be interested in it. they said no. esl is for deaf people.</td>\n",
       "      <td>0.583353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>the board has also been working with iad.</td>\n",
       "      <td>the board has also been working to provide leadership training</td>\n",
       "      <td>0.582132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.577830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.572429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>over time, qabil's personality became more</td>\n",
       "      <td>qabil is adam's twin sister.</td>\n",
       "      <td>0.572011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>he uses a scary situation to humble jacob when he’s about to see esau.</td>\n",
       "      <td>jacob often goes through trials and sanctification,</td>\n",
       "      <td>0.567977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>juice</td>\n",
       "      <td>milk</td>\n",
       "      <td>0.559592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>so i'm really interested in seeing how this all turns out</td>\n",
       "      <td>so i think this is going to be really exciting</td>\n",
       "      <td>0.552448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>hey! all you had do past stay</td>\n",
       "      <td>past can easy, all you have to do past stay</td>\n",
       "      <td>0.552438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>not only that, if i'm eating, i can sign at the same time.</td>\n",
       "      <td>i sign because if a friend is deaf,</td>\n",
       "      <td>0.550719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>that is my favorite quote</td>\n",
       "      <td>i'm a new follower of your favorite quote</td>\n",
       "      <td>0.550136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>democracy, creative things, stories about life, among other things. she’s also bisexual and occasionally makes videos about that.</td>\n",
       "      <td>i’m going to start with a video about her life, what she did, and how she feels about it.</td>\n",
       "      <td>0.545357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>don't fully understand the concepts behind economics.</td>\n",
       "      <td>but it's still the same. for example, the government says that the market</td>\n",
       "      <td>0.542002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>like deaf history, deaf jokes, and deaf story telling.</td>\n",
       "      <td>i'm deaf.</td>\n",
       "      <td>0.536357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>that meeting is open to the seven committee members, as well as the board and staff</td>\n",
       "      <td>the certification committee also has an appointed board liaison.</td>\n",
       "      <td>0.528021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>result from the body's response to the virus.</td>\n",
       "      <td>it could be because the antibodies become too weak</td>\n",
       "      <td>0.520274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>start a quiz means that you're ready to have students take a test.</td>\n",
       "      <td>we're going to focus on quizzes.</td>\n",
       "      <td>0.511093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>expected on senate and house floor</td>\n",
       "      <td>the house and senate are proposing</td>\n",
       "      <td>0.508235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>another thing that we don't know is the antibody tests,</td>\n",
       "      <td>if they were to become immune, they would have to undergo</td>\n",
       "      <td>0.501458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1. fundraising coordinator</td>\n",
       "      <td>2. camp responsibilities &amp;amp; duties :</td>\n",
       "      <td>0.501206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>the mismatch between the hearing teachers’ teaching style and the deaf students’ learning style.</td>\n",
       "      <td>these strategies will include parental involvement, awareness, and support for deaf awareness and access to education.</td>\n",
       "      <td>0.498222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>of the coming day of the lord again,</td>\n",
       "      <td>zechariah will reign on the earth,</td>\n",
       "      <td>0.498029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>many sound off performances were created specifically for the festival,</td>\n",
       "      <td>but it's the stage where the festival is being held.</td>\n",
       "      <td>0.497978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>the board, like any other board of any non profit agency, has legal responsibilities that they are obligated to meet.</td>\n",
       "      <td>the board does not hold a public meeting until the rid board approves the recommendation.</td>\n",
       "      <td>0.496599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>now, how to score your paths.</td>\n",
       "      <td>if a path starts with '1', the path ends with the next path.</td>\n",
       "      <td>0.490578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                               caption  \\\n",
       "404                                                                                                                    praise the lord   \n",
       "601                                                                                                                                fox   \n",
       "624                                                                                                                          delicious   \n",
       "217                                                                                              rainbows rainbows high up in the sky,   \n",
       "581                                                                                                                          a d grade   \n",
       "418                                                                                          scrub your hands for at least 20 seconds.   \n",
       "440                                                                                              school performances for deaf children   \n",
       "309                                                                                        raindrops, raindrops falling to the ground.   \n",
       "608                                                                                                          he called himself, \"i am\"   \n",
       "698                                                                                a radical life of discipleship to those around him!   \n",
       "12                                                                                                                                  27   \n",
       "591                                                                                                              welcome to sign1news.   \n",
       "692                                                                                         you are my sunshine my only&nbsp; sunshine   \n",
       "658                                                                                                              welcome to sign1news.   \n",
       "93                                                                                                                       baby and dad!   \n",
       "77                                                                                      my second asl professor's name was will white.   \n",
       "348                                                                                                again, the number is (866) 246 0133   \n",
       "71                                                                                            snowflake, right? slowly, slowly. right?   \n",
       "397                                                                                                                               pink   \n",
       "346                                                                                                                                  5   \n",
       "662                        the interpreting and deaf communities may look at these messages, empathize with their similar experiences,   \n",
       "157                                                                                    n: it's hot, we've been out at sea for so long.   \n",
       "246                                                         language delays are from a lack of exposure to early language development.   \n",
       "5                                                                         the boy gets sad when he realizes his gum is no longer there   \n",
       "45                                                                          see that? i sign what's west and east for me, not for you.   \n",
       "514                                                     the deaf studies department emailed me the application forms and instructions.   \n",
       "400                                                                                          the board has also been working with iad.   \n",
       "207                                                                                                                                  3   \n",
       "133                                                                                                                                  2   \n",
       "708                                                                                         over time, qabil's personality became more   \n",
       "699                                                             he uses a scary situation to humble jacob when he’s about to see esau.   \n",
       "154                                                                                                                              juice   \n",
       "518                                                                          so i'm really interested in seeing how this all turns out   \n",
       "421                                                                                                      hey! all you had do past stay   \n",
       "353                                                                         not only that, if i'm eating, i can sign at the same time.   \n",
       "706                                                                                                          that is my favorite quote   \n",
       "609  democracy, creative things, stories about life, among other things. she’s also bisexual and occasionally makes videos about that.   \n",
       "317                                                                              don't fully understand the concepts behind economics.   \n",
       "200                                                                             like deaf history, deaf jokes, and deaf story telling.   \n",
       "97                                                 that meeting is open to the seven committee members, as well as the board and staff   \n",
       "480                                                                                      result from the body's response to the virus.   \n",
       "335                                                                 start a quiz means that you're ready to have students take a test.   \n",
       "161                                                                                                 expected on senate and house floor   \n",
       "587                                                                            another thing that we don't know is the antibody tests,   \n",
       "20                                                                                                          1. fundraising coordinator   \n",
       "167                                   the mismatch between the hearing teachers’ teaching style and the deaf students’ learning style.   \n",
       "350                                                                                               of the coming day of the lord again,   \n",
       "340                                                            many sound off performances were created specifically for the festival,   \n",
       "548              the board, like any other board of any non profit agency, has legal responsibilities that they are obligated to meet.   \n",
       "622                                                                                                      now, how to score your paths.   \n",
       "\n",
       "                                                                                                                      prediction  \\\n",
       "404                                                                                                              praise the lord   \n",
       "601                                                                                                                          fox   \n",
       "624                                                                                                                    delicious   \n",
       "217                                                                                         rainbows rainbow high up in the sky.   \n",
       "581                                                                                                                    a c grade   \n",
       "418                                                                                          dry your hands using a clean towel.   \n",
       "440                                                                                  encouraging deaf performers to participate.   \n",
       "309                                                                                                                   raindrops.   \n",
       "608                                                                                                 jesus called himself, \"i am\"   \n",
       "698                                                                                          a radical life of obedience to god.   \n",
       "12                                                                                                                            25   \n",
       "591                                                                                                                   sign1news.   \n",
       "692                                                                                                          you are my sunshine   \n",
       "658                                                                                            thank you for watching sign1news.   \n",
       "93                                                                                                                 baby and boy!   \n",
       "77                                                                          my second asl professor's name was robert sanderson.   \n",
       "348                                                                                        the phone number is: +61 866 328 8933   \n",
       "71                                                                                                         snowflakes snowflake?   \n",
       "397                                                                                                                        white   \n",
       "346                                                                                                                            1   \n",
       "662                                                               social media has become a tool of empowerment for deaf people.   \n",
       "157                                                                                            a: i miss fish. m: it's too fast.   \n",
       "246                                                language deprivation is when a child is unable to understand spoken language.   \n",
       "5                                                                              the little boy sees a bench where he puts his gum   \n",
       "45                                      if you're going to be the \"right\" direction, you sign as you would see it. you go right.   \n",
       "514  so i asked them to help me with my application and if they would be interested in it. they said no. esl is for deaf people.   \n",
       "400                                                               the board has also been working to provide leadership training   \n",
       "207                                                                                                                            8   \n",
       "133                                                                                                                            8   \n",
       "708                                                                                                 qabil is adam's twin sister.   \n",
       "699                                                                          jacob often goes through trials and sanctification,   \n",
       "154                                                                                                                         milk   \n",
       "518                                                                               so i think this is going to be really exciting   \n",
       "421                                                                                  past can easy, all you have to do past stay   \n",
       "353                                                                                          i sign because if a friend is deaf,   \n",
       "706                                                                                    i'm a new follower of your favorite quote   \n",
       "609                                    i’m going to start with a video about her life, what she did, and how she feels about it.   \n",
       "317                                                    but it's still the same. for example, the government says that the market   \n",
       "200                                                                                                                    i'm deaf.   \n",
       "97                                                              the certification committee also has an appointed board liaison.   \n",
       "480                                                                           it could be because the antibodies become too weak   \n",
       "335                                                                                             we're going to focus on quizzes.   \n",
       "161                                                                                           the house and senate are proposing   \n",
       "587                                                                    if they were to become immune, they would have to undergo   \n",
       "20                                                                                       2. camp responsibilities &amp; duties :   \n",
       "167       these strategies will include parental involvement, awareness, and support for deaf awareness and access to education.   \n",
       "350                                                                                           zechariah will reign on the earth,   \n",
       "340                                                                         but it's the stage where the festival is being held.   \n",
       "548                                    the board does not hold a public meeting until the rid board approves the recommendation.   \n",
       "622                                                                 if a path starts with '1', the path ends with the next path.   \n",
       "\n",
       "     st_cos_sim  \n",
       "404    1.000000  \n",
       "601    1.000000  \n",
       "624    1.000000  \n",
       "217    0.970885  \n",
       "581    0.920364  \n",
       "418    0.894355  \n",
       "440    0.863475  \n",
       "309    0.833784  \n",
       "608    0.830660  \n",
       "698    0.824819  \n",
       "12     0.818956  \n",
       "591    0.817963  \n",
       "692    0.810030  \n",
       "658    0.796849  \n",
       "93     0.755276  \n",
       "77     0.745749  \n",
       "348    0.740335  \n",
       "71     0.699171  \n",
       "397    0.651829  \n",
       "346    0.633682  \n",
       "662    0.627510  \n",
       "157    0.623841  \n",
       "246    0.618356  \n",
       "5      0.615374  \n",
       "45     0.591377  \n",
       "514    0.583353  \n",
       "400    0.582132  \n",
       "207    0.577830  \n",
       "133    0.572429  \n",
       "708    0.572011  \n",
       "699    0.567977  \n",
       "154    0.559592  \n",
       "518    0.552448  \n",
       "421    0.552438  \n",
       "353    0.550719  \n",
       "706    0.550136  \n",
       "609    0.545357  \n",
       "317    0.542002  \n",
       "200    0.536357  \n",
       "97     0.528021  \n",
       "480    0.520274  \n",
       "335    0.511093  \n",
       "161    0.508235  \n",
       "587    0.501458  \n",
       "20     0.501206  \n",
       "167    0.498222  \n",
       "350    0.498029  \n",
       "340    0.497978  \n",
       "548    0.496599  \n",
       "622    0.490578  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pred.sort_values('st_cos_sim', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deanna-emery\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4a49eb94e54dc69fb6a6066bdc139a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !huggingface-cli whoami\n",
    "# model = TFAutoModelForSeq2SeqLM.from_pretrained(\"deanna-emery/ASL_t5_word_epoch15_1204\")\n",
    "\n",
    "\n",
    "# model.save_pretrained(\"/home/ec2-user/ASL-Translator/modeling/t5_word_epoch12_1203\")\n",
    "model.push_to_hub(\"deanna-emery/ASL_t5_movinet_sentence\", revision=\"sent_epoch10_1206\")\n",
    "# trainer.save_model(\"path/to/model\")\n",
    "\n",
    "# test = TFT5ForConditionalGeneration.from_pretrained(\"/home/ec2-user/ASL-Translator/modeling/t5_i3d_epoch5_1201\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  i will show you the step by step process that goes into picking out and cleaning your trophy case.\n",
      "true label:  they're very sharp.\n",
      "\n",
      "prediction:  you want to look for something that can be easily maneuvered through, and if you're not familiar with that type of climbing you can always call an experienced professional to come to your aid.\n",
      "true label:  then go back in and massage it into your scalp cause you are going to want to moisturize your hair.\n",
      "\n",
      "prediction:  and, that's going to be our last line in this little story.\n",
      "true label:  let us talk about oily skin first.\n",
      "\n",
      "prediction:  you want to always make sure that your kite has an approved service contract with your mechanic so that you can be sure you get the job done right the first time.\n",
      "true label:  now, slowly begin to connect these movements, exhaling as you drop the chin toward the chest and inhaling as the ear rolls up towards the shoulder blades, and do this as long as you're comfortable.\n",
      "\n",
      "prediction:  we all need that.\n",
      "true label:  now, the front squat develops your teardrop.\n",
      "\n",
      "prediction:  i'm not going to say anything about it, but this is what a good, healthy, balanced, low cal diet should look like.\n",
      "true label:  but those are basically what you do and usually there's three types of naps and we'll get into that in a second.\n",
      "\n",
      "prediction:  we'll take a little bit and put it on our picture frame.\n",
      "true label:  so, the best tasting vodka drink would be a dirty martini.\n",
      "\n",
      "prediction:  one, two, three, four.\n",
      "true label:  it's working with less time on you and less energy.\n",
      "\n",
      "prediction:  these are the top three things you want to consider when you're negotiating with a vendor.\n",
      "true label:  ok folks, in this clip i'm going to teach you how to draw a cartoon fly.\n",
      "\n",
      "prediction:  there is a good chance that you may actually be able to locate the person that the number is looking for, but this is not advisable.\n",
      "true label:  notice how my shoulders don't creep up--[sounds like] errk--as i drop the ear down, right?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try training on just WLASL and MSASL\n",
    "\n",
    "inputs = next(iter(train_dataset.batch(10)))\n",
    "test_outputs = model.generate(inputs_embeds = inputs['inputs_embeds'], attention_mask=inputs['attention_mask'],  \n",
    "                              max_new_tokens=128, \n",
    "                              # num_beams=2, \n",
    "                              no_repeat_ngram_size=2,\n",
    "                              do_sample=True,\n",
    "                              top_k=80, \n",
    "                              top_p=0.90, # try 0.5 and 0.2\n",
    "                              # early_stopping=True,\n",
    "                             ) # TOP-K TOP-P\n",
    "\n",
    "predictions = tokenizer.batch_decode(test_outputs, skip_special_tokens=True)\n",
    "test_labels = tokenizer.batch_decode(inputs['labels'], skip_special_tokens=True)\n",
    "\n",
    "for pred, lab in zip(predictions, test_labels):\n",
    "    print('prediction: ', pred)\n",
    "    print('true label: ', lab)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbBDnqVWtYgH",
    "outputId": "75a6a2ee-549a-4e0f-8c32-a8d1c248e99e"
   },
   "outputs": [],
   "source": [
    "# # training\n",
    "# inputs = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"tf\").input_ids\n",
    "# labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"tf\").input_ids\n",
    "# outputs = model(inputs, labels=labels)\n",
    "# loss = outputs.loss\n",
    "# logits = outputs.logits\n",
    "# print(loss)\n",
    "# print(logits)\n",
    "\n",
    "# # inference\n",
    "# inputs = tokenizer(\n",
    "#    [ \"studies have shown that owning a cat is good for you\", \"i have always wanted to have a pet\"], return_tensors=\"pt\", padding=True\n",
    "# ).input_ids  # Batch size 1\n",
    "\n",
    "# # Convert from tokens to embeddings\n",
    "# encoder_outputs = encoder_model(input_ids=inputs)\n",
    "# encoder_outputs['last_hidden_state'] = encoder_outputs['last_hidden_state'].detach().numpy()\n",
    "# print(encoder_outputs['last_hidden_state'].shape)\n",
    "\n",
    "# # Generate text from embeddings\n",
    "# outputs = model.generate(encoder_outputs=encoder_outputs)\n",
    "# # outputs = model.generate(inputs)\n",
    "\n",
    "\n",
    "# print(\"Response: \\n\")\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "# # studies have shown that owning a dog is good for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hD6yhZPALVUt",
    "outputId": "87076b0e-ba90-4269-97e8-74794f73af4a"
   },
   "outputs": [],
   "source": [
    "# # training\n",
    "# embeddings = tf.convert_to_tensor(vid_embedding)\n",
    "# mask = tf.convert_to_tensor(attention_mask)\n",
    "\n",
    "# labels = tokenizer(captions, return_tensors=\"tf\", padding=True).input_ids\n",
    "# outputs = model(input_ids=None, inputs_embeds=embeddings, \n",
    "#                      attention_mask=mask, labels=labels, training=True)\n",
    "# print(outputs.loss)\n",
    "# # loss = outputs.loss\n",
    "# # logits = outputs.logits\n",
    "# # print(loss)\n",
    "# # print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "J-8afj87146c",
    "outputId": "21c725b1-ac99-450d-a04f-32eb438ca160"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tensorflow/lib/python3.10/site-packages/transformers/generation/tf_utils.py:838: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "2023-11-08 04:39:47.301175: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55703850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-08 04:39:47.301212: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2023-11-08 04:39:47.408791: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-08 04:39:47.854060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8903\n",
      "2023-11-08 04:39:48.206243: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s its its it so it. so when it so it so it so it'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.generate(encoder_outputs=encoder_outputs)\n",
    "# tokenizer.decode(model.generate(inputs_embeds=encoder_outputs)[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FeqVf-KnNIh"
   },
   "outputs": [],
   "source": [
    "# def movinet_T5_model(video_base_model, language_base_model,\n",
    "#                       max_sequence_length=120,\n",
    "#                       hidden_size = 1024,\n",
    "#                       dropout=0.1,\n",
    "#                       learning_rate=0.00005):\n",
    "#     \"\"\"\n",
    "#     Builds a translation model that accepts videos, creates video embeddings using a MoViNet model,\n",
    "#     and then passes the video embeddings into an encoder-decoder to generate text translation\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Set all models to trainable\n",
    "#     video_base_model.trainable = True\n",
    "#     language_base_model.trainable = True\n",
    "\n",
    "#     # Set input structure for video inputs\n",
    "#     video_inputs = tf.keras.layers.Input(shape=(max_sequence_length, 256, 256, 3), dtype=tf.int64, name='input_layer')\n",
    "#     # token_type_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "#     attention_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "#     # Get output embeddings from video model\n",
    "#     movinet_out = video_base_model(video_inputs)\n",
    "#     vid_embedding = movinet_out[0]['block4_layer3']\n",
    "\n",
    "#     # Layer to flatten w x h x c dimensions\n",
    "#     vid_embedding_flatten = tf.keras.layers.Reshape((120, 8 * 8 * 168), name='flatten')(vid_embedding)\n",
    "\n",
    "#     # Hidden layer to force embeddings into correct shape for language model\n",
    "#     vid_embedding_flatten = tf.keras.layers.Dense(1024, activation='linear', name='hidden_layer')(vid_embedding_flatten)\n",
    "\n",
    "#     # # Pass embeddings into T5 language model\n",
    "#     # language_output = language_base_model.generate(encoder_outputs=encoder_outputs, attention_mask=attention_mask)\n",
    "\n",
    "#     # classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "\n",
    "#     # classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "\n",
    "#     # classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#     #                              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "#     #                              metrics='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "#     ### END YOUR CODE\n",
    "\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=vid_embedding_flatten)\n",
    "\n",
    "#     return model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05fc3b60f8d141e996b22059c9a7ca09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0701ca98a52745a9a6981e0ec6b25d7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08743108f461407d804357c0dbf6ded7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "098322ea0ed94efb946bffb6cbcfec25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f2bc280945e4521ac50a48302d55ee2",
      "placeholder": "​",
      "style": "IPY_MODEL_a54bda6555174aad910291160a5741de",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "0a28ab105a7647959914a094d68d9b5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e0d36daeda3441791d3e7ca21a7b097": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5583644bec2d4be1a889338aede2859e",
      "max": 607,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b73926262334455b671fa33d31eadd9",
      "value": 607
     }
    },
    "113fe85010e74cb4b535157febf808e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1a345df9d904996b2423960655673ff",
      "placeholder": "​",
      "style": "IPY_MODEL_3e8b1c7ca5ed42ba80703728543a09c1",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "119885c300d84755ae30152641ddc866": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "148c585f4ddf406681b05b1daf27227d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b951dfaf385457fadd2f1e1d2bc7785",
      "max": 1786,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb3d0d3d20dc47d39aef1798b0a4f637",
      "value": 1786
     }
    },
    "1b6fc395e4c14b95a9c2624a8d0aa211": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dd59591368343d19923a0c5e0169bc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e24e4a1f6564cb7aa61af39ce310283": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1efebdbb775c4ba3b6b5d465b1605930": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "244d17e04a4f41d285503960087ce67e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_098322ea0ed94efb946bffb6cbcfec25",
       "IPY_MODEL_148c585f4ddf406681b05b1daf27227d",
       "IPY_MODEL_c35c2d9a151d4e899fd935fd7c95a3b9"
      ],
      "layout": "IPY_MODEL_6457a5ad2c5c465490a79036edd15c1f"
     }
    },
    "247b5875632a4134adc870e7e9b241ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcc438b1d54d4a2192fbf13d16723a67",
      "placeholder": "​",
      "style": "IPY_MODEL_6c8fa39a797748db8d87444310adb049",
      "value": " 3.13G/3.13G [00:44&lt;00:00, 97.1MB/s]"
     }
    },
    "2a410589229442c5a08b1e19aae62c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bccfe21423e4b65af8997a314e51921",
      "placeholder": "​",
      "style": "IPY_MODEL_acf6a8e5f44c4638aeb38b6984a69ca8",
      "value": "Downloading (…)ve/main/spiece.model: 100%"
     }
    },
    "2e39b5786e294d638372db2e143fc70a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97749df1adfa4535b0d38aac2b028f02",
      "max": 3132858253,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6285176e71c941d69d1b82cbbdcee879",
      "value": 3132858253
     }
    },
    "3b73926262334455b671fa33d31eadd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3d61cbf445824ae681019e743a97b8fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a09bca0d594942aa93f097a4ffa58c1d",
      "placeholder": "​",
      "style": "IPY_MODEL_8d75ab215a4140b5b58ae71110ff187f",
      "value": " 3.13G/3.13G [00:57&lt;00:00, 92.4MB/s]"
     }
    },
    "3e8b1c7ca5ed42ba80703728543a09c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41f196dea0004e958c91fc628c19c771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46ec6504b7504b76959615555e610ddd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b951dfaf385457fadd2f1e1d2bc7785": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d580ef8885c4837b16566ac52929fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bde961601a7f446ba7b5bb4e2fafbeaf",
       "IPY_MODEL_2e39b5786e294d638372db2e143fc70a",
       "IPY_MODEL_3d61cbf445824ae681019e743a97b8fe"
      ],
      "layout": "IPY_MODEL_1b6fc395e4c14b95a9c2624a8d0aa211"
     }
    },
    "53f1249d01e44f1eb846b90a9ac3f21a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8185ffd3cdce4433ae54c559ab75cb57",
      "max": 1857,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76f81bba35c74daaa131d293b74f16f6",
      "value": 1857
     }
    },
    "5583644bec2d4be1a889338aede2859e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bccfe21423e4b65af8997a314e51921": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f52628b5aca41078df434e961292f4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62383dac2ba2405d855b6bea35b0358a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa8f77c6ed7a40c68591f8843caef5a0",
       "IPY_MODEL_64d82bcf90de412c85f03b5bf157c0d7",
       "IPY_MODEL_ddabb3d36b794288bb3d8db94107c84a"
      ],
      "layout": "IPY_MODEL_e2a7daa66f574bde9248fde4487d6c08"
     }
    },
    "6285176e71c941d69d1b82cbbdcee879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63feb6f007894f8ba0554139e1d95ad9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6457a5ad2c5c465490a79036edd15c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64d82bcf90de412c85f03b5bf157c0d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70828d14ca154e80a0ebb08a44a4e270",
      "max": 147,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa04001aa5994a94bb8bf4b05fb8d156",
      "value": 147
     }
    },
    "67355b68cba847eba42038f9dce8b8ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67a00b046d254e0ab4473317c637059e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69eed7e8d4db4bf883ea69cf788cd5fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c8fa39a797748db8d87444310adb049": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f2bc280945e4521ac50a48302d55ee2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70828d14ca154e80a0ebb08a44a4e270": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7506923b6a8f4cffbe94dd9194d5ef78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76f81bba35c74daaa131d293b74f16f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "775bb9dd303347dcadf0604b02d233b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80d6ccb946c240cfbcb10a91f8c44c79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a17d3747768746bd9cc19a9bb07dd8f1",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41f196dea0004e958c91fc628c19c771",
      "value": 791656
     }
    },
    "8185ffd3cdce4433ae54c559ab75cb57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8721eacce4b44913a798a82e44ca10a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dd59591368343d19923a0c5e0169bc0",
      "placeholder": "​",
      "style": "IPY_MODEL_cc21a0b25944497a844d8a1fc36fcc5d",
      "value": " 1.86k/1.86k [00:00&lt;00:00, 89.2kB/s]"
     }
    },
    "8ce503ec21094870b987d9fef0c1364d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d75ab215a4140b5b58ae71110ff187f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97749df1adfa4535b0d38aac2b028f02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "983815eaf4a5449e88dee260fc3cb986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab3bf657fe1c47aeb9a05a5de0832f20",
      "max": 3133710136,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0701ca98a52745a9a6981e0ec6b25d7d",
      "value": 3133710136
     }
    },
    "9dd8f481e1de48429cbe8f3c41b3361c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ce503ec21094870b987d9fef0c1364d",
      "placeholder": "​",
      "style": "IPY_MODEL_63feb6f007894f8ba0554139e1d95ad9",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "a09bca0d594942aa93f097a4ffa58c1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a17d3747768746bd9cc19a9bb07dd8f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a54bda6555174aad910291160a5741de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa04001aa5994a94bb8bf4b05fb8d156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab3bf657fe1c47aeb9a05a5de0832f20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac7f8914736f4b5eaa1390537cc39d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d287c8fe184f41369fa597626cb1b12b",
      "placeholder": "​",
      "style": "IPY_MODEL_d0669d9654564c049d9c0b28e6655c47",
      "value": " 792k/792k [00:00&lt;00:00, 5.83MB/s]"
     }
    },
    "acf6a8e5f44c4638aeb38b6984a69ca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad51dcd5891e45cca9a290a9a744d28c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_113fe85010e74cb4b535157febf808e8",
       "IPY_MODEL_0e0d36daeda3441791d3e7ca21a7b097",
       "IPY_MODEL_bcd00e6c788f46aea761913b87c7331b"
      ],
      "layout": "IPY_MODEL_5f52628b5aca41078df434e961292f4a"
     }
    },
    "af517973c08c4bac83127ece0ea4964b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb3d0d3d20dc47d39aef1798b0a4f637": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bcc438b1d54d4a2192fbf13d16723a67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcd00e6c788f46aea761913b87c7331b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_775bb9dd303347dcadf0604b02d233b8",
      "placeholder": "​",
      "style": "IPY_MODEL_7506923b6a8f4cffbe94dd9194d5ef78",
      "value": " 607/607 [00:00&lt;00:00, 31.6kB/s]"
     }
    },
    "bdc0d514733c4e049429752530e10643": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a410589229442c5a08b1e19aae62c23",
       "IPY_MODEL_80d6ccb946c240cfbcb10a91f8c44c79",
       "IPY_MODEL_ac7f8914736f4b5eaa1390537cc39d31"
      ],
      "layout": "IPY_MODEL_67a00b046d254e0ab4473317c637059e"
     }
    },
    "bde961601a7f446ba7b5bb4e2fafbeaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69eed7e8d4db4bf883ea69cf788cd5fe",
      "placeholder": "​",
      "style": "IPY_MODEL_05fc3b60f8d141e996b22059c9a7ca09",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "c35c2d9a151d4e899fd935fd7c95a3b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe7f16ce9e774787a956d5a3fc77c7ed",
      "placeholder": "​",
      "style": "IPY_MODEL_1e24e4a1f6564cb7aa61af39ce310283",
      "value": " 1.79k/1.79k [00:00&lt;00:00, 120kB/s]"
     }
    },
    "c8730bc225c448ed83d03c980411ec37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9dd8f481e1de48429cbe8f3c41b3361c",
       "IPY_MODEL_53f1249d01e44f1eb846b90a9ac3f21a",
       "IPY_MODEL_8721eacce4b44913a798a82e44ca10a6"
      ],
      "layout": "IPY_MODEL_08743108f461407d804357c0dbf6ded7"
     }
    },
    "cc21a0b25944497a844d8a1fc36fcc5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccb7103fbd924eedb25f994580153855": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d79218f755c74875b5bcb07a9b1f0b54",
       "IPY_MODEL_983815eaf4a5449e88dee260fc3cb986",
       "IPY_MODEL_247b5875632a4134adc870e7e9b241ac"
      ],
      "layout": "IPY_MODEL_119885c300d84755ae30152641ddc866"
     }
    },
    "d0669d9654564c049d9c0b28e6655c47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1a345df9d904996b2423960655673ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d287c8fe184f41369fa597626cb1b12b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d79218f755c74875b5bcb07a9b1f0b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb525cc2161b4a668cf42f4397847ebe",
      "placeholder": "​",
      "style": "IPY_MODEL_af517973c08c4bac83127ece0ea4964b",
      "value": "Downloading tf_model.h5: 100%"
     }
    },
    "ddabb3d36b794288bb3d8db94107c84a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46ec6504b7504b76959615555e610ddd",
      "placeholder": "​",
      "style": "IPY_MODEL_1efebdbb775c4ba3b6b5d465b1605930",
      "value": " 147/147 [00:00&lt;00:00, 2.53kB/s]"
     }
    },
    "e2a7daa66f574bde9248fde4487d6c08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb525cc2161b4a668cf42f4397847ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa8f77c6ed7a40c68591f8843caef5a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a28ab105a7647959914a094d68d9b5a",
      "placeholder": "​",
      "style": "IPY_MODEL_67355b68cba847eba42038f9dce8b8ba",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "fe7f16ce9e774787a956d5a3fc77c7ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
