{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq-TetgsJmOv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4gdz81fMlnP"
      },
      "outputs": [],
      "source": [
        "!pip install gensim --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOSnMqiYMlnP"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu8MIPByMlnP",
        "outputId": "683de03c-5a8d-4ac2-e084-21f7a5a05a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m5.7/6.0 MB\u001b[0m \u001b[31m172.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow-text --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-4vXVxKMlnQ"
      },
      "source": [
        "pydot is also required, along with **graphviz**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbN0SnpZMlnQ"
      },
      "outputs": [],
      "source": [
        "!pip install pydot --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3fGCI9BMlnQ"
      },
      "source": [
        "Ready to do the imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju4oXKFYMlnQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "# import sklearn as sk\n",
        "import os\n",
        "# import nltk\n",
        "# from nltk.data import find\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "\n",
        "# import gensim\n",
        "# from gensim.models import Word2Vec\n",
        "# from gensim.models import KeyedVectors\n",
        "# from gensim.test.utils import datapath"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1 has 3 caption\n",
        "v2 has 4 captions\n",
        "\n",
        "\n",
        "\n",
        "X_train = [v1c1, v1c2, v1c3, [v2c1, v2c2, v2c3, v2c4]]\n",
        "where\n",
        "v1c1 shape = [720, 1280]\n",
        "\n",
        "y_train = [c1,c2,c3,c1,c2,c3,c4]"
      ],
      "metadata": {
        "id": "oAFqALlPLOsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2023 The Google Research Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Model defination for the I3D Video Model.\"\"\"\n",
        "\n",
        "import functools\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class Unit3D(tf.keras.layers.Layer):\n",
        "  \"\"\"The main 3D unit that contains Conv3D + BN.\"\"\"\n",
        "\n",
        "  def __init__(self, output_channels,\n",
        "               kernel_size=(1, 1, 1),\n",
        "               strides=(1, 1, 1),\n",
        "               activation_fn=tf.nn.relu,\n",
        "               use_batch_norm=True,\n",
        "               use_bias=False,\n",
        "               use_xreplica_bn=True,\n",
        "               bn_kwargs=None,\n",
        "               name='unit_3d',\n",
        "               **kwargs):\n",
        "    super(Unit3D, self).__init__(name=name, **kwargs)\n",
        "    bn_kwargs = bn_kwargs or {}\n",
        "    self._use_batch_norm = use_batch_norm\n",
        "    self._activation_fn = activation_fn\n",
        "    self.conv3d = tf.keras.layers.Conv3D(\n",
        "        filters=output_channels,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        use_bias=use_bias,\n",
        "        padding='same',\n",
        "        name='conv_3d'\n",
        "        )\n",
        "\n",
        "    if use_xreplica_bn:\n",
        "      bn_fn = tf.keras.layers.experimental.SyncBatchNormalization\n",
        "    else:\n",
        "      bn_fn = tf.keras.layers.BatchNormalization\n",
        "    self.bn = bn_fn(name='batch_norm', **bn_kwargs)\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    out = self.conv3d(inputs)\n",
        "    if self._use_batch_norm:\n",
        "      out = self.bn(out, training=training)\n",
        "    if self._activation_fn is not None:\n",
        "      out = self._activation_fn(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Mixed(tf.keras.layers.Layer):\n",
        "  \"\"\"The 3D Inception block.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               filter_map,\n",
        "               use_xreplica_bn,\n",
        "               bn_kwargs=None,\n",
        "               name='mixed',\n",
        "               **kwargs):\n",
        "    super(Mixed, self).__init__(name=name, **kwargs)\n",
        "    self.unit3d_b0_0 = Unit3D(output_channels=filter_map['branch_0'],\n",
        "                              kernel_size=[1, 1, 1],\n",
        "                              use_xreplica_bn=use_xreplica_bn,\n",
        "                              bn_kwargs=bn_kwargs,\n",
        "                              name='conv3d_0a_1x1')\n",
        "    self.unit3d_b1_0 = Unit3D(output_channels=filter_map['branch_1'][0],\n",
        "                              kernel_size=[1, 1, 1],\n",
        "                              use_xreplica_bn=use_xreplica_bn,\n",
        "                              bn_kwargs=bn_kwargs,\n",
        "                              name='conv3d_0a_1x1')\n",
        "    self.unit3d_b1_1 = Unit3D(output_channels=filter_map['branch_1'][1],\n",
        "                              kernel_size=[3, 3, 3],\n",
        "                              use_xreplica_bn=use_xreplica_bn,\n",
        "                              bn_kwargs=bn_kwargs,\n",
        "                              name='conv3d_0b_3x3')\n",
        "    self.unit3d_b2_0 = Unit3D(output_channels=filter_map['branch_2'][0],\n",
        "                              kernel_size=[1, 1, 1],\n",
        "                              use_xreplica_bn=use_xreplica_bn,\n",
        "                              bn_kwargs=bn_kwargs,\n",
        "                              name='conv3d_0a_1x1')\n",
        "    self.unit3d_b2_1 = Unit3D(output_channels=filter_map['branch_2'][1],\n",
        "                              kernel_size=[3, 3, 3],\n",
        "                              use_xreplica_bn=use_xreplica_bn,\n",
        "                              bn_kwargs=bn_kwargs,\n",
        "                              name='conv3d_0b_3x3')\n",
        "    self.max3d_b3_0 = tf.keras.layers.MaxPool3D(pool_size=[3, 3, 3],\n",
        "                                                strides=[1, 1, 1],\n",
        "                                                padding='same',\n",
        "                                                name='maxpool3d_0a_3x3')\n",
        "    self.unit3d_b3_1 = Unit3D(output_channels=filter_map['branch_3'],\n",
        "                              kernel_size=[1, 1, 1],\n",
        "                              use_xreplica_bn=use_xreplica_bn,\n",
        "                              bn_kwargs=bn_kwargs,\n",
        "                              name='conv3d_0b_1x1')\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    with tf.name_scope('branch_0'):\n",
        "      branch_0 = self.unit3d_b0_0(inputs, training=training)\n",
        "\n",
        "    with tf.name_scope('branch_1'):\n",
        "      branch_1 = self.unit3d_b1_0(inputs, training=training)\n",
        "      branch_1 = self.unit3d_b1_1(branch_1, training=training)\n",
        "\n",
        "    with tf.name_scope('branch_2'):\n",
        "      branch_2 = self.unit3d_b2_0(inputs, training=training)\n",
        "      branch_2 = self.unit3d_b2_1(branch_2, training=training)\n",
        "\n",
        "    with tf.name_scope('branch_3'):\n",
        "      branch_3 = self.max3d_b3_0(inputs)\n",
        "      branch_3 = self.unit3d_b3_1(branch_3, training=training)\n",
        "\n",
        "    output = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n",
        "    return output\n",
        "\n",
        "\n",
        "class InceptionI3D(tf.keras.layers.Layer):\n",
        "  \"\"\"Inception I3D Model.\"\"\"\n",
        "  _FEATURE_LAYERS = [\n",
        "      'conv3d_1a_7x7',\n",
        "      'maxpool3d_2a_3x3',\n",
        "      'conv3d_2b_1x1',\n",
        "      'conv3d_2c_3x3',\n",
        "      'maxpool3d_3a_3x3',\n",
        "      'mixed_3b',\n",
        "      'mixed_3c',\n",
        "      'maxpool3d_4a_3x3',\n",
        "      'mixed_4b',\n",
        "      'mixed_4c',\n",
        "      'mixed_4d',\n",
        "      'mixed_4e',\n",
        "      'mixed_4f',\n",
        "      'maxpool3d_5a_2x2',\n",
        "      'mixed_5b',\n",
        "      'mixed_5c'\n",
        "  ]\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes=None,\n",
        "               use_xreplica_bn=True,\n",
        "               batch_norm_decay=0.99,\n",
        "               batch_norm_epsilon=0.001,\n",
        "               batch_norm_scale=True,\n",
        "               dropout_rate=0.2,\n",
        "               data_format='channels_last',\n",
        "               name='i3d_backbone',\n",
        "               **kwargs):\n",
        "\n",
        "    super(InceptionI3D, self).__init__(name=name)\n",
        "    self.num_classes = num_classes\n",
        "    bn_kwargs = {'momentum': batch_norm_decay,\n",
        "                 'epsilon': batch_norm_epsilon,\n",
        "                 'scale': batch_norm_scale}\n",
        "    self.conv3d_1a_7x7 = Unit3D(output_channels=64,\n",
        "                                kernel_size=[7, 7, 7],\n",
        "                                strides=[2, 2, 2],\n",
        "                                use_xreplica_bn=use_xreplica_bn,\n",
        "                                bn_kwargs=bn_kwargs,\n",
        "                                name='conv3d_1a_7x7')\n",
        "    self.maxpool3d_2a_3x3 = tf.keras.layers.MaxPool3D(pool_size=[1, 3, 3],\n",
        "                                                      strides=[1, 2, 2],\n",
        "                                                      padding='same',\n",
        "                                                      name='maxpool3d_2a_3x3')\n",
        "    self.conv3d_2b_1x1 = Unit3D(output_channels=64,\n",
        "                                kernel_size=[1, 1, 1],\n",
        "                                use_xreplica_bn=use_xreplica_bn,\n",
        "                                bn_kwargs=bn_kwargs,\n",
        "                                name='conv3d_2b_1x1')\n",
        "    self.conv3d_2c_3x3 = Unit3D(output_channels=192,\n",
        "                                kernel_size=[3, 3, 3],\n",
        "                                use_xreplica_bn=use_xreplica_bn,\n",
        "                                bn_kwargs=bn_kwargs,\n",
        "                                name='conv3d_2c_3x3')\n",
        "    self.maxpool3d_3a_3x3 = tf.keras.layers.MaxPool3D(pool_size=[1, 3, 3],\n",
        "                                                      strides=[1, 2, 2],\n",
        "                                                      padding='same',\n",
        "                                                      name='maxpool3d_3a_3x3')\n",
        "    self.mixed_3b = Mixed(filter_map={'branch_0': 64,\n",
        "                                      'branch_1': [96, 128],\n",
        "                                      'branch_2': [16, 32],\n",
        "                                      'branch_3': 32},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_3b')\n",
        "    self.mixed_3c = Mixed(filter_map={'branch_0': 128,\n",
        "                                      'branch_1': [128, 192],\n",
        "                                      'branch_2': [32, 96],\n",
        "                                      'branch_3': 64},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_3c')\n",
        "    self.maxpool3d_4a_3x3 = tf.keras.layers.MaxPool3D(pool_size=[3, 3, 3],\n",
        "                                                      strides=[2, 2, 2],\n",
        "                                                      padding='same',\n",
        "                                                      name='maxpool3d_4a_3x3')\n",
        "    self.mixed_4b = Mixed(filter_map={'branch_0': 192,\n",
        "                                      'branch_1': [96, 208],\n",
        "                                      'branch_2': [16, 48],\n",
        "                                      'branch_3': 64},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_4b')\n",
        "    self.mixed_4c = Mixed(filter_map={'branch_0': 160,\n",
        "                                      'branch_1': [112, 224],\n",
        "                                      'branch_2': [24, 64],\n",
        "                                      'branch_3': 64},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_4c')\n",
        "    self.mixed_4d = Mixed(filter_map={'branch_0': 128,\n",
        "                                      'branch_1': [128, 256],\n",
        "                                      'branch_2': [24, 64],\n",
        "                                      'branch_3': 64},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_4d')\n",
        "    self.mixed_4e = Mixed(filter_map={'branch_0': 112,\n",
        "                                      'branch_1': [144, 288],\n",
        "                                      'branch_2': [32, 64],\n",
        "                                      'branch_3': 64},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_4e')\n",
        "    self.mixed_4f = Mixed(filter_map={'branch_0': 256,\n",
        "                                      'branch_1': [160, 320],\n",
        "                                      'branch_2': [32, 128],\n",
        "                                      'branch_3': 128},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_4f')\n",
        "    self.maxpool3d_5a_2x2 = tf.keras.layers.MaxPool3D(pool_size=[2, 2, 2],\n",
        "                                                      strides=[2, 2, 2],\n",
        "                                                      padding='same',\n",
        "                                                      name='maxpool3d_5a_2x2')\n",
        "    self.mixed_5b = Mixed(filter_map={'branch_0': 256,\n",
        "                                      'branch_1': [160, 320],\n",
        "                                      'branch_2': [32, 128],\n",
        "                                      'branch_3': 128},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_5b')\n",
        "    self.mixed_5c = Mixed(filter_map={'branch_0': 384,\n",
        "                                      'branch_1': [192, 384],\n",
        "                                      'branch_2': [48, 128],\n",
        "                                      'branch_3': 128},\n",
        "                          use_xreplica_bn=use_xreplica_bn,\n",
        "                          bn_kwargs=bn_kwargs,\n",
        "                          name='mixed_5c')\n",
        "\n",
        "    pool_dims = self._get_pool_dims(data_format)\n",
        "    self.avgpool3d_la = functools.partial(tf.reduce_mean, axis=pool_dims)\n",
        "\n",
        "  def _get_pool_dims(self, data_format):\n",
        "    if data_format == 'channels_last':\n",
        "      return [1, 2, 3]\n",
        "    else:\n",
        "      return [2, 3, 4]\n",
        "\n",
        "  def freeze_backbone(self):\n",
        "    for layer_name in self._FEATURE_LAYERS:\n",
        "      layer = getattr(self, layer_name)\n",
        "      layer.trainable = False\n",
        "\n",
        "  def unfreeze_backbone(self):\n",
        "    for layer_name in self._FEATURE_LAYERS:\n",
        "      layer = getattr(self, layer_name)\n",
        "      layer.trainable = True\n",
        "\n",
        "  def freeze_classification_layer(self):\n",
        "    self.conv3d_0c_1x1.trainable = False\n",
        "\n",
        "  def unfreeze_classification_layer(self):\n",
        "    self.conv3d_0c_1x1.trainable = True\n",
        "\n",
        "  def call(self,\n",
        "           inputs,\n",
        "           training):\n",
        "\n",
        "    endpoints = {}\n",
        "    for layer_name in self._FEATURE_LAYERS:\n",
        "      layer = getattr(self, layer_name)\n",
        "      if 'maxpool3d' in layer_name:\n",
        "        inputs = layer(inputs)\n",
        "      else:\n",
        "        inputs = layer(inputs, training)\n",
        "      endpoints[layer_name] = inputs\n",
        "\n",
        "    features_pooled = self.avgpool3d_la(inputs)\n",
        "    return features_pooled, endpoints"
      ],
      "metadata": {
        "id": "9YOTBZpHKzVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now specify model hyperparameters and call the function to create a CNN model\n",
        "\n",
        "num_filters = [100, 100, 50, 25]\n",
        "kernel_sizes = [3, 4, 5, 10]\n",
        "dense_layer_dims = [100, 50]\n",
        "dropout_rate = 0.5\n",
        "\n",
        "cnn_model = build_cnn_model(num_filters, kernel_sizes, dense_layer_dims, dropout_rate)"
      ],
      "metadata": {
        "id": "W36yNWUmK4M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2023 The Google Research Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Factory to build video classification model.\"\"\"\n",
        "import collections\n",
        "import functools\n",
        "import logging\n",
        "from typing import Any, Dict, Mapping, Text, Union, Optional\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from vatt.configs import factory as configs_factory\n",
        "from vatt.configs import video as video_config\n",
        "from vatt.modeling.backbones.video import i3d\n",
        "from vatt.modeling.backbones.video import vitx3d\n",
        "\n",
        "\n",
        "def get_shape(x):\n",
        "  \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
        "  static = x.shape.as_list()\n",
        "  dynamic = tf.shape(x)\n",
        "  return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "\n",
        "class PredictionAggregator(tf.keras.layers.Layer):\n",
        "  \"\"\"Aggregates test predictions.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_test_clips = 1,\n",
        "               name = 'aggregate_clips'):\n",
        "\n",
        "    super(PredictionAggregator, self).__init__(name=name)\n",
        "    self._num_test_clips = num_test_clips\n",
        "\n",
        "  def call(self,\n",
        "           inputs,\n",
        "           training = None):\n",
        "    if training or self._num_test_clips == 1:\n",
        "      return inputs\n",
        "\n",
        "    else:\n",
        "      def aggregate(inputs):\n",
        "        d_features = get_shape(inputs)[-1]\n",
        "        return tf.reduce_mean(\n",
        "            tf.reshape(inputs,\n",
        "                       [-1, self._num_test_clips, d_features]),\n",
        "            axis=1,\n",
        "            )\n",
        "\n",
        "      return tf.nest.map_structure(aggregate, inputs)\n",
        "\n",
        "\n",
        "class VideoModel(tf.keras.Model):\n",
        "  \"\"\"Constructs Video model with (potential) head.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               base_model,\n",
        "               params,\n",
        "               pred_aggregator = None):\n",
        "    \"\"\"VideoModel.\"\"\"\n",
        "\n",
        "    super(VideoModel, self).__init__(name='video_module')\n",
        "    self._model_name = params.name\n",
        "    self._freeze_backbone = params.freeze_backbone\n",
        "    self._dropout_rate = params.cls_dropout_rate\n",
        "    self._final_endpoint = params.final_endpoint\n",
        "    self._num_classes = params.num_classes\n",
        "    self._ops = collections.OrderedDict()\n",
        "\n",
        "    base_kwargs = params.as_dict()\n",
        "    if 'backbone_config' in base_kwargs:\n",
        "      base_kwargs['backbone_config'] = params.backbone_config\n",
        "\n",
        "    self._base = base_model(**base_kwargs)\n",
        "\n",
        "    if self._freeze_backbone:\n",
        "      self._base.trainable = False\n",
        "\n",
        "    if self._num_classes is not None:\n",
        "      self._ops['dropout'] = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
        "      cls_name = 'classification/weights'\n",
        "      self._ops['cls'] = tf.keras.layers.Dense(\n",
        "          self._num_classes,\n",
        "          kernel_initializer='glorot_normal',\n",
        "          name=cls_name,\n",
        "          )\n",
        "      pred_name = 'classification/probabilities'\n",
        "      self._ops['softmax'] = functools.partial(tf.nn.softmax, name=pred_name)\n",
        "      self._loss_object = tf.keras.losses.CategoricalCrossentropy(\n",
        "          reduction=tf.keras.losses.Reduction.NONE\n",
        "          )\n",
        "\n",
        "    self.pred_aggregator = pred_aggregator\n",
        "\n",
        "  def loss_fn(self,\n",
        "              labels,\n",
        "              outputs,\n",
        "              replicator):\n",
        "\n",
        "    del replicator\n",
        "    loss = self._loss_object(labels['one_hot'], outputs['probabilities'])\n",
        "    loss = tf.reduce_mean(loss)\n",
        "\n",
        "    losses = {'model_loss': loss}\n",
        "    l2_loss = tf.reduce_sum(self.losses) / 2\n",
        "    total_loss = losses['model_loss'] + tf.cast(l2_loss,\n",
        "                                                losses['model_loss'].dtype)\n",
        "\n",
        "    losses.update({'regularization_loss': l2_loss,\n",
        "                   'total_loss': total_loss})\n",
        "\n",
        "    return losses\n",
        "\n",
        "  def call(self,  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks\n",
        "           inputs,\n",
        "           training = None):\n",
        "    \"\"\"Call the layer.\n",
        "\n",
        "    Args:\n",
        "      inputs: input tensors of different modalities. E.g., RGB, optical flow.\n",
        "      training: True for in the training mode.\n",
        "\n",
        "    Returns:\n",
        "      output_dict: a dict of model outputs, including one of the features,\n",
        "      logits and probabilities, depending on the configs\n",
        "    \"\"\"\n",
        "    if isinstance(inputs, dict):\n",
        "      data = inputs['images']\n",
        "    else:\n",
        "      data = inputs\n",
        "\n",
        "    # for dropout and batch_norm. Especially for fuse logits layers.\n",
        "    features_pooled, end_points = self._base(data, training=training)\n",
        "    features = end_points[self._final_endpoint]\n",
        "\n",
        "    if self._freeze_backbone:\n",
        "      features = tf.stop_gradient(features)\n",
        "      features_pooled = tf.stop_gradient(features_pooled)\n",
        "\n",
        "    outputs = {'features': features,\n",
        "               'features_pooled': features_pooled}\n",
        "\n",
        "    if self._num_classes is None:\n",
        "      return outputs\n",
        "\n",
        "    features_pooled = self._ops['dropout'](features_pooled, training)\n",
        "    logits = self._ops['cls'](features_pooled)\n",
        "    if self.pred_aggregator is not None:\n",
        "      logits = self.pred_aggregator(logits, training)\n",
        "    probabilities = self._ops['softmax'](logits)\n",
        "\n",
        "    outputs = {\n",
        "        'logits': logits,\n",
        "        'probabilities': probabilities\n",
        "    }\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def build_model(\n",
        "    params = None,\n",
        "    override_params = None,\n",
        "    backbone = None,\n",
        "    mode = 'embedding',\n",
        "    ):\n",
        "  \"\"\"Build model by name.\"\"\"\n",
        "  if params is None:\n",
        "    assert backbone is not None, 'either params or backbone should be specified'\n",
        "    params = configs_factory.build_model_configs(backbone)\n",
        "\n",
        "  if override_params is not None:\n",
        "    params.override(override_params)\n",
        "\n",
        "  model_name = params.name\n",
        "  if model_name.startswith('i3d'):\n",
        "    base_model = i3d.InceptionI3D\n",
        "  elif model_name.startswith('vit'):\n",
        "    base_model = vitx3d.ViTx3D\n",
        "  else:\n",
        "    raise ValueError('Unknown backbone {!r}'.format(model_name))\n",
        "\n",
        "  if mode == 'predict':\n",
        "    pred_aggregator = PredictionAggregator(\n",
        "        num_test_clips=params.num_test_samples\n",
        "        )\n",
        "  else:\n",
        "    pred_aggregator = None\n",
        "\n",
        "  model = VideoModel(\n",
        "      base_model=base_model,\n",
        "      params=params,\n",
        "      pred_aggregator=pred_aggregator,\n",
        "      )\n",
        "\n",
        "  logging.info('Video model %s created successfully.', params.name)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "XkhTU58-u17R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vid_backbone = build_model(\n",
        "        backbone=\"resnet50\",\n",
        "        mode=\"embedding\",\n",
        "        )\n",
        "\n",
        "backbone_outputs = vid_backbone(video, training=training)\n",
        "\n",
        "video_outputs = {\"features\": backbone_outputs[\"features\"],\n",
        "                  \"features_pooled\": backbone_outputs[\"features_pooled\"]}"
      ],
      "metadata": {
        "id": "2RTbFkEIu3HF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}