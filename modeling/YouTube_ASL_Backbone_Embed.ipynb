{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27e1e23-dac5-4414-920b-27d9c1e75064",
   "metadata": {},
   "source": [
    "### Purpose of notebook\n",
    "The purpose of this notebook is to pass the YouTube ASL videos through the MoviNet backbone and then save its output back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d8871c-78e0-43ff-bd9f-2d3d950858a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's not show unnecessary warnings etc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552897ab-4f96-4ad9-8eed-8b78a10f35d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/.aws/credentials']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/ec2-user/.aws/credentials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c261c2-7c81-45ca-963b-ebf1a5112600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials and S3 settings\n",
    "aws_access_key_id = config[\"default\"]['aws_access_key_id']\n",
    "aws_secret_access_key = config[\"default\"]['aws_secret_access_key']\n",
    "bucket_name = 'asl-capstone'\n",
    "s3_URI = 's3://asl-capstone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bccdf3cc-2111-4930-9e3f-53cbec6ccd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(key=aws_access_key_id, secret=aws_secret_access_key)\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3',aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key,\n",
    "                  region_name = 'us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e8f36b-657a-4a90-90d9-534df6f71616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 03:17:28.846350: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 03:17:28.846401: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 03:17:28.846421: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 03:17:28.853820: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 03:17:29.759792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries. Keep adding here as you code\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841a3636-946a-4455-b2c9-5e41e80e388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/models\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "%cd /home/ec2-user/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43818e80-121e-484b-bcd6-e20506f03209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are going to use\n",
    "model_version = 'a3'\n",
    "\n",
    "if model_version=='a3':\n",
    "  max_frames = 120\n",
    "  image_dims = (256,256)\n",
    "elif model_version=='a0':\n",
    "  max_frames = 50\n",
    "  image_dims = (172,172)\n",
    "elif model_version=='a5':\n",
    "  max_frames = 120\n",
    "  image_dims = (320,302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a11dbc-2db0-4660-b5c5-384fb3383e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 labels.\n"
     ]
    }
   ],
   "source": [
    "# Get the kinetics-600 action labels\n",
    "KINETICS_URL = \"official/projects/movinet/files/kinetics_600_labels.txt\"\n",
    "with open(KINETICS_URL) as obj:\n",
    "  labels_600 = [line for line in obj.readlines()]\n",
    "print(\"Found %d labels.\" % len(labels_600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8927f97-1ad6-45db-b622-0c53e7b05dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 03:17:35.523963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:35.545787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:35.547773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:35.550381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:35.552294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:35.554035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:36.028058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:36.029004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:36.029746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 03:17:36.030459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20591 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Create the backbone using the Movinet model\n",
    "from official.projects.movinet.modeling import movinet\n",
    "\n",
    "# Create backbone and model.\n",
    "backbone = movinet.Movinet(\n",
    "    model_id=model_version, #change to correspond to model\n",
    "    causal=False,\n",
    "    use_external_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6695dca-577c-4a5e-8bab-132a2bb65136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59042\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the numpy files from S3\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "video_files = []\n",
    "for page in paginator.paginate(Bucket = bucket_name, Prefix = 'youtube-asl/1000-samples/numpy_files/'):\n",
    "    video_files.extend(content['Key'] for content in page.get('Contents',[]) if content['Key'].endswith(('.npy')))\n",
    "print(len(video_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b28c59-5460-4da8-8e65-aea3786906ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the S3 prefix\n",
    "video_files = ['s3://asl-capstone/'+x for x in video_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc95fbd0-e61d-4365-9cb1-174a67d847fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's break this into batches\n",
    "video_files = video_files[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62996823-b7e0-4daa-b433-e859f860f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration batch\n",
    "iteration_1 = video_files[:5000]\n",
    "iteration_2 = video_files[5001:10000]\n",
    "iteration_3 = video_files[10001:15000]\n",
    "iteration_4 = video_files[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37bafece-1b91-44fe-8c40-dfe179a94368",
   "metadata": {},
   "outputs": [],
   "source": [
    "movinet_uri = 's3://asl-capstone/youtube-asl/1000-samples/movinet/backbone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19ffbf15-40df-41d9-8d29-7be41d72fc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://asl-capstone/youtube-asl/1000-samples/numpy_files/--6bmFM9wT4_0.npy\n"
     ]
    }
   ],
   "source": [
    "print(iteration_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0735afd7-0a75-4f2f-acfd-f8c2c7c90082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/5000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Initialize the progress bar with the total number of iterations\n",
    "#pbar = tqdm(total=len(iteration_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a179147-9b3c-4469-ace9-0246acdfee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                               | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                                                                                                                    | 1/5000 [00:12<17:48:04, 12.82s/it]\u001b[A\n",
      "  0%|                                                                                                                                                                    | 2/5000 [00:48<33:25:22, 24.07s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(vid)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(vid,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m     vid_file \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m vid_file \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(vid_file, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m backbone(vid_file)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock4_layer3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/numpy/lib/format.py:823\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    821\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    822\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 823\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    825\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/numpy/lib/format.py:958\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 958\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/fsspec/spec.py:1858\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1858\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/fsspec/caching.py:156\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    154\u001b[0m     part \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, end \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# new block replaces old\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m=\u001b[39m start\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache)\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/s3fs/core.py:2220\u001b[0m, in \u001b[0;36mS3File._fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch_range\u001b[39m(\u001b[38;5;28mself\u001b[39m, start, end):\n\u001b[1;32m   2219\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2220\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fetch_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreq_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreq_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m   2231\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ex\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mEINVAL \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre-conditions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ex\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/s3fs/core.py:2382\u001b[0m, in \u001b[0;36m_fetch_range\u001b[0;34m(fs, bucket, key, version_id, start, end, req_kw)\u001b[0m\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2381\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetch: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, bucket, key, start, end)\n\u001b[0;32m-> 2382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_inner_fetch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/fsspec/asyn.py:91\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# this loops allows thread to get interrupted\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for vid in tqdm(iteration_1):\n",
    "    # Generate video embeddings and store to CPU\n",
    "    filename = os.path.basename(vid)\n",
    "    with fs.open(vid,\"rb\") as f:\n",
    "        vid_file = np.load(f)\n",
    "    vid_file = np.expand_dims(vid_file, axis=0)\n",
    "    embeddings = backbone(vid_file)[0]['block4_layer3'].cpu().numpy()\n",
    "    with fs.open(f\"{movinet_uri+filename}\",\"wb\") as f:\n",
    "        np.save(f,embeddings)\n",
    "    #pbar.update(1)\n",
    "#pbar.close() #Closing the bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcf4c8-c8e4-4c64-aa42-cc14aa3f28ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
