{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27e1e23-dac5-4414-920b-27d9c1e75064",
   "metadata": {},
   "source": [
    "### Purpose of notebook\n",
    "The purpose of this notebook is to pass the YouTube ASL videos through the MoviNet backbone and then save its output back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d8871c-78e0-43ff-bd9f-2d3d950858a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's not show unnecessary warnings etc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552897ab-4f96-4ad9-8eed-8b78a10f35d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/.aws/credentials']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/ec2-user/.aws/credentials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c261c2-7c81-45ca-963b-ebf1a5112600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials and S3 settings\n",
    "aws_access_key_id = config[\"default\"]['aws_access_key_id']\n",
    "aws_secret_access_key = config[\"default\"]['aws_secret_access_key']\n",
    "bucket_name = 'asl-capstone'\n",
    "s3_URI = 's3://asl-capstone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bccdf3cc-2111-4930-9e3f-53cbec6ccd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(key=aws_access_key_id, secret=aws_secret_access_key)\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3',aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key,\n",
    "                  region_name = 'us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e8f36b-657a-4a90-90d9-534df6f71616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries. Keep adding here as you code\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import dask\n",
    "from dask.distributed import Client, progress, as_completed\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841a3636-946a-4455-b2c9-5e41e80e388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/models\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "%cd /home/ec2-user/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43818e80-121e-484b-bcd6-e20506f03209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are going to use\n",
    "model_version = 'a3'\n",
    "\n",
    "if model_version=='a3':\n",
    "  max_frames = 120\n",
    "  image_dims = (256,256)\n",
    "elif model_version=='a0':\n",
    "  max_frames = 50\n",
    "  image_dims = (172,172)\n",
    "elif model_version=='a5':\n",
    "  max_frames = 120\n",
    "  image_dims = (320,302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a11dbc-2db0-4660-b5c5-384fb3383e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 labels.\n"
     ]
    }
   ],
   "source": [
    "# Get the kinetics-600 action labels\n",
    "KINETICS_URL = \"official/projects/movinet/files/kinetics_600_labels.txt\"\n",
    "with open(KINETICS_URL) as obj:\n",
    "  labels_600 = [line for line in obj.readlines()]\n",
    "print(\"Found %d labels.\" % len(labels_600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8927f97-1ad6-45db-b622-0c53e7b05dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:25:55.715877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:55.738908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:55.740771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:55.743183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:55.745070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:55.746947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:56.248737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:56.249708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:56.250458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:25:56.251161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20591 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Create the backbone using the Movinet model\n",
    "from official.projects.movinet.modeling import movinet\n",
    "\n",
    "# Create backbone and model.\n",
    "backbone = movinet.Movinet(\n",
    "    model_id=model_version, #change to correspond to model\n",
    "    causal=False,\n",
    "    use_external_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6695dca-577c-4a5e-8bab-132a2bb65136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59042\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the numpy files from S3\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "video_files = []\n",
    "for page in paginator.paginate(Bucket = bucket_name, Prefix = 'youtube-asl/1000-samples/numpy_files/'):\n",
    "    video_files.extend(content['Key'] for content in page.get('Contents',[]) if content['Key'].endswith(('.npy')))\n",
    "print(len(video_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b28c59-5460-4da8-8e65-aea3786906ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the S3 prefix\n",
    "video_files = ['s3://asl-capstone/'+x for x in video_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc95fbd0-e61d-4365-9cb1-174a67d847fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's break this into batches\n",
    "video_files = video_files[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62996823-b7e0-4daa-b433-e859f860f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration batch\n",
    "iteration_1 = video_files[348:5000]\n",
    "iteration_2 = video_files[5001:10000]\n",
    "iteration_3 = video_files[10001:15000]\n",
    "iteration_4 = video_files[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e08f856-3695-4566-a68f-bae11da3d229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 µs, sys: 1 µs, total: 37 µs\n",
      "Wall time: 41.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iteration_2 = iteration_2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d51fb6-6257-4984-86a3-3f9d92297f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                  | 0/5 [00:00<?, ?it/s]2023-11-18 04:29:22.021732: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x278a4780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-18 04:29:22.021774: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2023-11-18 04:29:22.852413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8903\n",
      "2023-11-18 04:29:23.651424: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x7f6ae587c1f0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x7f6ae587e290>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:From <timed exec>:8: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity with explicit device placement instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████████                                                                                                                                        | 1/5 [00:20<01:22, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with processing s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_19.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████████████████████████                                                                                                      | 2/5 [00:41<01:01, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with processing s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3/5 [00:58<00:38, 19.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with processing s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_20.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4/5 [01:17<00:18, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with processing s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_21.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:36<00:00, 19.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with processing s3://asl-capstone/youtube-asl/1000-samples/numpy_files/4zPLsd-C7cI_22.npy\n",
      "CPU times: user 1min 11s, sys: 1.79 s, total: 1min 12s\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# for vid in tqdm(iteration_2):\n",
    "#     try:\n",
    "#         # Generate video embeddings and store to CPU\n",
    "#         filename = os.path.basename(vid)\n",
    "#         with fs.open(vid,\"rb\") as f:\n",
    "#             vid_file = np.load(f)\n",
    "#         vid_file = np.expand_dims(vid_file, axis=0)\n",
    "#         embeddings = backbone(vid_file)[0]['block4_layer9'].cpu().numpy()\n",
    "#         with fs.open(f\"{movinet_uri+filename}\",\"wb\") as f:\n",
    "#             np.save(f,embeddings)\n",
    "#     except:\n",
    "#         print(f\"Error with processing {vid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37bafece-1b91-44fe-8c40-dfe179a94368",
   "metadata": {},
   "outputs": [],
   "source": [
    "movinet_uri = 's3://asl-capstone/youtube-asl/1000-samples/movinet/backbone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a83377f0-adc3-43bd-bfae-6075fcfa1d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "http://172.31.13.102:34807/status\n"
     ]
    }
   ],
   "source": [
    "# Start a Dask client\n",
    "client = Client(processes=False)\n",
    "# Print the link to the dashboard\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfb09b8f-2148-47cb-8455-e66a877c827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(vid):\n",
    "  # Add a try except\n",
    "  try:\n",
    "      # Generate video embeddings and store to CPU\n",
    "      filename = os.path.basename(vid)\n",
    "      with fs.open(vid,\"rb\") as f:\n",
    "          vid_file = np.load(f)\n",
    "      vid_file = np.expand_dims(vid_file, axis=0)\n",
    "      embeddings = backbone(vid_file)[0]['block4_layer9'].cpu().numpy()\n",
    "      with fs.open(f\"{movinet_uri+filename}\",\"wb\") as f:\n",
    "          np.save(f,embeddings)\n",
    "  except:\n",
    "      print(f\"Error with processing {vid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "921c3504-43a7-4a7d-b986-d90bbe2ba751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:17<00:00,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 8.31 s, total: 3min 16s\n",
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Use Dask's map function to apply the process_video function to each video\n",
    "futures = client.map(process_video, iteration_2)\n",
    "\n",
    "# Create a progress bar with tqdm\n",
    "progress_bar = tqdm(total=len(iteration_2))\n",
    "\n",
    "# Use as_completed to update the progress bar as futures complete\n",
    "for future in as_completed(futures):\n",
    "    result = future.result()  # This blocks until the future is complete\n",
    "    progress_bar.update()\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "# Wait for all futures to complete\n",
    "client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcf4c8-c8e4-4c64-aa42-cc14aa3f28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_id():\n",
    "    \"\"\"Get current instance ID from metadata\"\"\"\n",
    "    url = \"http://169.254.169.254/latest/meta-data/instance-id\"\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b261e-54c7-4464-93a5-d52174228f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_instance(instance_id, region_name='us-west-2'):\n",
    "    \"\"\"Stop the EC2 instance\"\"\"\n",
    "    ec2 = boto3.client('ec2', aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key, region_name=region_name)\n",
    "    ec2.stop_instances(InstanceIds=[instance_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814a122-8307-46a1-aedc-33303ccfc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current instance ID\n",
    "instance_id = get_instance_id()\n",
    "print(instance_id)\n",
    "# Stop the instance\n",
    "stop_instance(instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f42037-b829-458d-b0a7-2fc5159669b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
