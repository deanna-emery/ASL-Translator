{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e8d3aa-e373-48f7-b22e-14fc4e30a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3 #Video files get read through this\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import s3fs # Parquet files get read through this\n",
    "import zlib # For compression\n",
    "import time # To calculate download time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6203efd-4219-4053-8aa4-29dccb7de335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy\n",
    "#!pip install cv2\n",
    "#!pip3 install opencv-python-headless\n",
    "#!pip install h5py\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f896a62b-9dee-405c-bbff-423c76e27fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/.aws/credentials']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/ec2-user/.aws/credentials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa9b8ef6-03ab-4faa-8315-11c0dad50f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials and S3 settings\n",
    "aws_access_key_id = config[\"root\"]['aws_access_key_id']\n",
    "aws_secret_access_key = config[\"root\"]['aws_secret_access_key']\n",
    "bucket_name = 'asl-capstone'\n",
    "prefix = 'youtube-asl/test_sample/'\n",
    "save_path = '/content/temp_folder'\n",
    "s3_URI = 's3://asl-capstone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fe3c67-bbb5-4638-ab0a-2381f7790531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Boto3 S3 client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-west-2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa1a35f6-650f-41f6-9559-e62cd286e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2654357d-038c-4f46-bf6b-b46fbdd430de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to retrieve file from S3: 1014.574492931366 seconds\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# AWS \n",
    "aws_access_key_id = config[\"root\"]['aws_access_key_id']\n",
    "aws_secret_access_key = config[\"root\"]['aws_secret_access_key']\n",
    "bucket_name = 'asl-capstone'\n",
    "prefix = 'youtube-asl/test_sample/'\n",
    "s3_URI = 's3://asl-capstone/'\n",
    "\n",
    "s3_file_key = prefix + 'numpy_files/RGB/padded_joined_videos_150.npy'\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=s3_file_key)\n",
    "    data = response['Body'].read()\n",
    "    \n",
    "    loaded_array = np.load(io.BytesIO(data))\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time to retrieve file from S3: {elapsed_time} seconds\")\n",
    "\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"NoSuchKey\":\n",
    "        print(\"The specified key does not exist.\")\n",
    "    else:\n",
    "        print(\"An error occurred: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eb41af1-70b0-4f13-8979-b564745c23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Not enough free space to write 9437184000 bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define the output .npy file path\n",
    "npy_file_path = 'padded_joined_videos_150.npy'\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Save the loaded_array as a .npy file\n",
    "    np.save(npy_file_path, loaded_array)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time to save loaded_array as a .npy file: {elapsed_time} seconds\")\n",
    "\n",
    "    # Print the location of the .npy file\n",
    "    print(f\"File saved at: {os.path.abspath(npy_file_path)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96b5dd8-9966-409e-9351-61b930273545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to store loaded_array in HDF5 file: 53.60840559005737 seconds\n",
      "File saved at: /home/ec2-user/ASL-Translator/data_processing/padded_joined_videos_150.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import time\n",
    "\n",
    "hdf5_file_path = 'padded_joined_videos_150.h5'\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create an HDF5 file and store the loaded_array in it\n",
    "    with h5py.File(hdf5_file_path, 'w') as hf:\n",
    "        hf.create_dataset('data', data=loaded_array)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time to store loaded_array in HDF5 file: {elapsed_time} seconds\")\n",
    "    \n",
    "    # Print the location of the HDF5 file\n",
    "    print(f\"File saved at: {os.path.abspath(hdf5_file_path)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100cb2f7-4cde-494e-a761-975712e2b6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to upload file to S3: 90.45855116844177 seconds\n",
      "File uploaded to S3: s3://asl-capstone/size_test/padded_joined_videos_150.h5\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import time\n",
    "\n",
    "# AWS credentials and S3 settings\n",
    "s3_folder = \"size_test\"  \n",
    "\n",
    "# Path to the local HDF5 file\n",
    "local_file_path = \"padded_joined_videos_150.h5\"\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Upload the file to S3 in the specified folder\n",
    "s3_object_key = f\"{s3_folder}/{os.path.basename(local_file_path)}\"\n",
    "s3.upload_file(local_file_path, bucket_name, s3_object_key)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time to upload file to S3: {elapsed_time} seconds\")\n",
    "print(f\"File uploaded to S3: s3://{bucket_name}/{s3_object_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e66757b-e325-4d56-8139-51cc30403b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to download and load HDF5 data from S3: 493.39018154144287 seconds\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import h5py\n",
    "import time\n",
    "import io\n",
    "\n",
    "# AWS credentials and S3 settings\n",
    "s3_folder = \"size_test\"  \n",
    "hdf5_file_name = \"padded_joined_videos_150.h5\"  \n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Download the HDF5 file from S3 and load it directly into memory\n",
    "s3_object_key = f\"{s3_folder}/{hdf5_file_name}\"\n",
    "response = s3.get_object(Bucket=bucket_name, Key=s3_object_key)\n",
    "data = response['Body'].read()\n",
    "\n",
    "end_time_download = time.time()\n",
    "elapsed_time_download = end_time_download - start_time\n",
    "print(f\"Time to download and load HDF5 data from S3: {elapsed_time_download} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272ffff-de97-451b-a173-976e43133fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 08:46:57.055131: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 08:46:57.959708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-08 08:46:57.959796: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-08 08:46:57.968116: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-08 08:46:58.409214: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 08:46:58.411966: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-08 08:47:01.294193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert loaded_array to a TensorFlow tensor\n",
    "loaded_tensor = tf.constant(loaded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f2e34-9ce8-45a7-a02e-547ceb96fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 08:25:21.153546: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 08:25:22.076725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-08 08:25:22.076821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-08 08:25:22.082138: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-08 08:25:22.548392: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 08:25:22.550805: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-08 08:25:25.487793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Convert loaded_array to a TensorFlow tensor\n",
    "loaded_tensor = tf.constant(loaded_array)\n",
    "\n",
    "# Define the output TensorFlow file path\n",
    "tf_file_path = 'padded_joined_videos_150.tf'\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Save the TensorFlow tensor as a TensorFlow file\n",
    "    tf.io.write_file(tf_file_path, loaded_tensor.numpy())\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time to store loaded_array as a TensorFlow file: {elapsed_time} seconds\")\n",
    "    \n",
    "    # Print the location of the TensorFlow file\n",
    "    print(f\"File saved at: {os.path.abspath(tf_file_path)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dd575-15cf-402d-b5d7-5a9fdd139b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
